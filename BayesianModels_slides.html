<!DOCTYPE html>
<html lang="en"><head>
<script src="BayesianModels_slides_files/libs/clipboard/clipboard.min.js"></script>
<script src="BayesianModels_slides_files/libs/quarto-html/tabby.min.js"></script>
<script src="BayesianModels_slides_files/libs/quarto-html/popper.min.js"></script>
<script src="BayesianModels_slides_files/libs/quarto-html/tippy.umd.min.js"></script>
<link href="BayesianModels_slides_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="BayesianModels_slides_files/libs/quarto-html/light-border.css" rel="stylesheet">
<link href="BayesianModels_slides_files/libs/quarto-html/quarto-syntax-highlighting-2f5df379a58b258e96c21c0638c20c03.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.6.42">

  <title>bayesianmodels_slides</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="BayesianModels_slides_files/libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="BayesianModels_slides_files/libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
    /* CSS for syntax highlighting */
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      { color: #003b4f; background-color: #f1f3f5; }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span { color: #003b4f; } /* Normal */
    code span.al { color: #ad0000; } /* Alert */
    code span.an { color: #5e5e5e; } /* Annotation */
    code span.at { color: #657422; } /* Attribute */
    code span.bn { color: #ad0000; } /* BaseN */
    code span.bu { } /* BuiltIn */
    code span.cf { color: #003b4f; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #20794d; } /* Char */
    code span.cn { color: #8f5902; } /* Constant */
    code span.co { color: #5e5e5e; } /* Comment */
    code span.cv { color: #5e5e5e; font-style: italic; } /* CommentVar */
    code span.do { color: #5e5e5e; font-style: italic; } /* Documentation */
    code span.dt { color: #ad0000; } /* DataType */
    code span.dv { color: #ad0000; } /* DecVal */
    code span.er { color: #ad0000; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #ad0000; } /* Float */
    code span.fu { color: #4758ab; } /* Function */
    code span.im { color: #00769e; } /* Import */
    code span.in { color: #5e5e5e; } /* Information */
    code span.kw { color: #003b4f; font-weight: bold; } /* Keyword */
    code span.op { color: #5e5e5e; } /* Operator */
    code span.ot { color: #003b4f; } /* Other */
    code span.pp { color: #ad0000; } /* Preprocessor */
    code span.sc { color: #5e5e5e; } /* SpecialChar */
    code span.ss { color: #20794d; } /* SpecialString */
    code span.st { color: #20794d; } /* String */
    code span.va { color: #111111; } /* Variable */
    code span.vs { color: #20794d; } /* VerbatimString */
    code span.wa { color: #5e5e5e; font-style: italic; } /* Warning */
  </style>
  <link rel="stylesheet" href="BayesianModels_slides_files/libs/revealjs/dist/theme/quarto-2f366650f320edcfcf53d73c80250a32.css">
  <link rel="stylesheet" href="BayesianModels_styles.css">
  <link href="BayesianModels_slides_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="BayesianModels_slides_files/libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="BayesianModels_slides_files/libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="BayesianModels_slides_files/libs/revealjs/plugin/reveal-chalkboard/font-awesome/css/all.css" rel="stylesheet">
  <link href="BayesianModels_slides_files/libs/revealjs/plugin/reveal-chalkboard/style.css" rel="stylesheet">
  <link href="BayesianModels_slides_files/libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
  <script src="https://cdn.plot.ly/plotly-latest.min.js"></script>
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">


<section class="slide level2">

<!-- #region Title slide -->
</section>
<section class="slide level2">

<div style="display: flex; flex-direction: column; align-items: center; height: 100vh; padding-top: 60px; text-align: center;">
<div style="font-size:1.6em; font-weight:bold; margin-bottom:10px; margin-top:10px;">
<pre><code>Bayesian Models of Brains, Minds, &amp; Behaviors </code></pre>
</div>
<div style="font-size:1.1em; margin-bottom:15px;">
<pre><code>DRCMR Â· Copenhagen Â· May 2025 </code></pre>
</div>
<div style="font-size:0.9em; max-width: 80%; margin: 0 auto;">
<pre><code>Ollie Hulme Â· David Meder Â· Janine BÃ¼hler Â· Melissa Larsen
    Amin Kangavari Â· Simon Steinkamp Â· Naiara Demnitz</code></pre>
</div>
<p><img src="images/DRCMR_regionH_KU_logo.png" alt="DRCMR logo" style="height:80px; margin-top:15px;"></p>
</div>
</section>
<section class="slide level2">

<!-- #endregion -->
<!-- #region Lecture#1 Preamble -->
</section>
<section id="lecture-1-preamble-roadmap" class="slide level2">
<h2>Lecture 1: Preamble â€” Roadmap</h2>
<ul>
<li class="fragment">What this course is about ğŸ§ <br>
</li>
<li class="fragment">Materials: GitHub, Binder, Book<br>
</li>
<li class="fragment">Schedule, social, and how the week works<br>
</li>
<li class="fragment">Group project: model minds &amp; brains<br>
</li>
<li class="fragment">Our vibe &amp; what we expect from you</li>
</ul>
</section>
<section id="how-the-week-will-go" class="slide level2">
<h2>How the week will go</h2>
<ul>
<li class="fragment">A mix of lectures, exercises, and group work<br>
</li>
<li class="fragment">Youâ€™ll build and present a model with your group<br>
</li>
<li class="fragment">Lectures lay the conceptual groundwork<br>
</li>
<li class="fragment">Most hands-on work happens in Jupyter notebooks<br>
</li>
<li class="fragment">Weâ€™re here to learn by doing</li>
</ul>
</section>
<section id="materials" class="slide level2">
<h2>Materials</h2>
<ul>
<li class="fragment">GitHub: slides, code, schedule<br>
</li>
<li class="fragment">Binder: run notebooks in browser, no install<br>
</li>
<li class="fragment">Book: key reference, especially early in the week<br>
</li>
<li class="fragment">WhatsApp: optional, but great for staying in sync<br>
</li>
<li class="fragment">All links in the GitHub <code>README.md</code></li>
</ul>
</section>
<section id="schedule" class="slide level2">
<h2>Schedule</h2>
<ul>
<li class="fragment">Up to date on GitHub<br>
</li>
<li class="fragment">Locations may change â€” check daily<br>
</li>
<li class="fragment">Each day blends concept and coding<br>
</li>
<li class="fragment">Friday = presentations &amp; bar ğŸ»<br>
</li>
<li class="fragment">Be curious, flexible, and collaborative</li>
</ul>
</section>
<section id="social" class="slide level2">
<h2>Social</h2>
<ul>
<li class="fragment">Join the WhatsApp group (link on GitHub)<br>
</li>
<li class="fragment">Ask questions, share thoughts, coordinate<br>
</li>
<li class="fragment">Friday = informal bar to celebrate</li>
</ul>
</section>
<section id="course-overview" class="slide level2">
<h2>Course overview</h2>
<ul>
<li class="fragment"><strong>Basic modelling</strong> â†’ Get started<br>
</li>
<li class="fragment"><strong>Intermediate modelling</strong> â†’ Go deeper<br>
</li>
<li class="fragment"><strong>Neural data integration</strong> â†’ Link brain &amp; behavior<br>
</li>
<li class="fragment"><strong>Group project</strong> â†’ Model, analyze, present<br>
</li>
<li class="fragment">â†“<br>
</li>
<li class="fragment">lectures Â· exercises Â· case studies Â· group work</li>
</ul>
</section>
<section id="course-schematic" class="slide level2">
<h2>Course schematic</h2>
<ul>
<li class="fragment"><img data-src="images/course_schema.jpg" style="width:100.0%"><br>
</li>
<li class="fragment">Your group project will follow this workflow</li>
</ul>
</section>
<section id="group-project" class="slide level2">
<h2>Group project</h2>
<ul>
<li class="fragment">Form a small group<br>
</li>
<li class="fragment">Pick a cognitive question<br>
</li>
<li class="fragment">Design an experiment (behavioral + neural)<br>
</li>
<li class="fragment">Build models to test your hypotheses<br>
</li>
<li class="fragment">Present your work on Friday (~15 min)</li>
</ul>
</section>
<section id="supervision-support" class="slide level2">
<h2>Supervision &amp; Support</h2>
<ul>
<li class="fragment">Janine: talk to her if youâ€™re shy or stuck<br>
</li>
<li class="fragment">Ollie &amp; David: logistics, schedule<br>
</li>
<li class="fragment">Simon: Binder, GitHub, Python<br>
</li>
<li class="fragment">Everyone: modeling, data, ideas â€” just ask</li>
</ul>
</section>
<section id="binder" class="slide level2">
<h2>Binder</h2>
<ul>
<li class="fragment">Launch notebooks in your browser<br>
</li>
<li class="fragment">No installation needed<br>
</li>
<li class="fragment">Be patient â€” it takes time to load<br>
</li>
<li class="fragment">Keep your Binder tab open all day<br>
<img src="/images/binder.png" width="300px"></li>
</ul>
</section>
<section id="github" class="slide level2">
<h2>GitHub</h2>
<ul>
<li class="fragment">Main hub for slides, code, notebooks, and schedule<br>
</li>
<li class="fragment">Just browse or clone the repo<br>
<img src="/images/github.png" width="300px"></li>
</ul>
</section>
<section id="book" class="slide level2">
<h2>Book</h2>
<ul>
<li class="fragment">Core reference for models &amp; theory<br>
</li>
<li class="fragment">Especially useful Monâ€“Wed<br>
</li>
<li class="fragment">Use it to deepen understanding<br>
<img src="/images/book.jpeg" width="300px"></li>
</ul>
</section>
<section id="whatsapp" class="slide level2">
<h2>WhatsApp</h2>
<ul>
<li class="fragment">Optional group chat<br>
</li>
<li class="fragment">Ask questions, coordinate, share<br>
</li>
<li class="fragment">Link is on GitHub <code>README.md</code><br>
<img src="/images/whatsapp.png" width="300px"></li>
</ul>
</section>
<section id="overarching-aim" class="slide level2">
<h2>Overarching aim</h2>
<ul>
<li class="fragment">Use probability theory to explain minds and behavior<br>
</li>
<li class="fragment">Upgrade your scientific reasoning<br>
</li>
<li class="fragment">Simplicity: intuitive, powerful tools<br>
</li>
<li class="fragment">Universality: same ideas apply across science<br>
</li>
<li class="fragment">From description â†’ explanation</li>
</ul>
</section>
<section id="specific-aims" class="slide level2">
<h2>Specific aims</h2>
<ul>
<li class="fragment">Build and test cognitive models<br>
</li>
<li class="fragment">Link behavior to neural data<br>
</li>
<li class="fragment">Be hands-on, interactive, exploratory<br>
</li>
<li class="fragment">Get messy â€” youâ€™ll learn by doing<br>
</li>
<li class="fragment">KISS: Keep It Simple, Stupid ğŸ˜œ</li>
</ul>
</section>
<section id="our-expectations-of-you" class="slide level2">
<h2>Our expectations of you</h2>
<ul>
<li class="fragment">Ask questions â€” donâ€™t nod and fake it<br>
</li>
<li class="fragment">Disrupt gently â€” curiosity is good<br>
</li>
<li class="fragment">You deserve to understand this<br>
</li>
<li class="fragment">Doubt is natural, confusion is common<br>
</li>
<li class="fragment">Letâ€™s work it out together</li>
</ul>
</section>
<section id="things-we-love-to-hear" class="slide level2">
<h2>Things we love to hear</h2>
<ul>
<li class="fragment">â€œI might have missed this, butâ€¦â€<br>
</li>
<li class="fragment">â€œCan I ask a stupid question?â€<br>
</li>
<li class="fragment">â€œDo you have an intuition for whyâ€¦â€<br>
</li>
<li class="fragment">â€œIâ€™m confusedâ€ ğŸ¤”<br>
</li>
<li class="fragment">Thatâ€™s how the real learning starts</li>
</ul>
</section>
<section id="things-not-to-do-to-yourself" class="slide level2">
<h2>Things not to do to yourself</h2>
<ul>
<li class="fragment">Donâ€™t pretend to get it<br>
</li>
<li class="fragment">Donâ€™t assume youâ€™re the only one confused<br>
</li>
<li class="fragment">Donâ€™t sit in silence out of self-doubt<br>
</li>
<li class="fragment">Speak up â€” youâ€™re helping the group</li>
</ul>
</section>
<section id="upcoming-lectures" class="slide level2">
<h2>Upcoming lectures</h2>
<ul>
<li class="fragment">Basics of Bayesian thinking<br>
</li>
<li class="fragment">Modeling cognition as a binary process<br>
</li>
<li class="fragment">Modeling mixtures of processes<br>
</li>
<li class="fragment">Selecting models<br>
</li>
<li class="fragment">Bayes factors and posterior odds<br>
</li>
<li class="fragment">Inference, prediction, and explaining minds</li>
</ul>
</section>
<section>
<section id="lecture-1-preamble" class="title-slide slide level1 center">
<h1>Lecture 1: Preamble</h1>
<ul>
<li class="fragment">How the week will go</li>
<li class="fragment">Materials<br>
</li>
<li class="fragment">Schedule<br>
</li>
<li class="fragment">Social ğŸ˜Š<br>
</li>
<li class="fragment">Aims &amp; expectations</li>
</ul>
</section>
<section id="course-overview-1" class="slide level2">
<h2>Course overview</h2>
<ul>
<li class="fragment"><strong>Basic modelling</strong> â†’ Get started</li>
<li class="fragment"><strong>Intermediate modelling</strong> â†’ Go deeper</li>
<li class="fragment"><strong>Integrate neural data</strong> â†’ Bridge brain &amp; behavior</li>
<li class="fragment"><strong>Group presentations</strong> â†’ Show what you built</li>
<li class="fragment">â†“</li>
<li class="fragment">lectures Â· interactive exercises Â· discussion Â· case studies Â· group work</li>
</ul>
</section>
<section id="overarching-schematic" class="slide level2">
<h2>Overarching schematic</h2>
<ul>
<li class="fragment"><img data-src="images/course_schema.jpg" style="width:100.0%"></li>
<li class="fragment">Your group project will reflect this workflow.</li>
</ul>
</section>
<section id="group-work-presentations" class="slide level2">
<h2>Group work &amp; presentations</h2>
<ul>
<li class="fragment"><strong>Separate</strong> into small groups</li>
<li class="fragment"><strong>Supervision</strong> from multiple experts</li>
<li class="fragment"><strong>Pick question</strong> that requires cognitive modelling</li>
<li class="fragment"><strong>Design experiment</strong> that collects behavioral &amp; neural data</li>
<li class="fragment"><strong>Design models</strong>, sketch graphical diagrams, plan analyses to test hypotheses &amp; answer question</li>
<li class="fragment"><strong>Present projects</strong>, share your work, ~15 mins on fri</li>
<li class="fragment"><strong>Audience</strong> questions &amp; discussion</li>
</ul>
</section>
<section id="materials-interactive-exercises" class="slide level2">
<h2>Materials: Interactive exercises</h2>
<ul>
<li class="fragment">Run interactive python code via Binder<br>
</li>
<li class="fragment">No installation needed â†’ just open in browser and go ğŸ˜Œ<br>
</li>
<li class="fragment">Loading takes time â†’ keep your tab open</li>
<li class="fragment"><div style="text-align: center;">
<p><img src="/images/binder.png" alt="binder screenshot" width="300px"></p>
</div></li>
<li class="fragment">link in footer ğŸ‘‡</li>
</ul>
</section>
<section id="materials-github" class="slide level2">
<h2>Materials: GitHub</h2>
<ul>
<li class="fragment">All materials + code on GitHub</li>
<li class="fragment"><div style="text-align: center;">
<p><img src="/images/github.png" alt="github screenshot" width="300px"></p>
</div></li>
<li class="fragment">link in footer ğŸ‘‡</li>
</ul>
</section>
<section id="materials-book" class="slide level2">
<h2>Materials: Book</h2>
<ul>
<li class="fragment"><div style="text-align: center;">
<img src="/images/book.jpeg" alt="book screenshot" width="300px">
</div></li>
<li class="fragment">We rely heavily on it especially on days 1-3</li>
</ul>
</section>
<section id="schedule-1" class="slide level2">
<h2>Schedule</h2>
<ul>
<li class="fragment">Up to date schedule &gt; See the GitHub &gt; README.md</li>
<li class="fragment">LOCATION CHANGES BY DAY</li>
</ul>
</section>
<section id="social-whatsapp" class="slide level2">
<h2>Social: WhatsApp</h2>
<ul>
<li class="fragment">Chat with each other ğŸ’¬</li>
<li class="fragment">Ask &amp; answer questions amongst yourselves ğŸ—£ï¸</li>
<li class="fragment">Stay in touch â¤ï¸</li>
<li class="fragment">Friday bar! ğŸ˜„</li>
<li class="fragment">Join group via ğŸ‘‡</li>
<li class="fragment"><img src="/images/whatsapp.png" width="300px"></li>
<li class="fragment">Link also on README.md of GitHub</li>
</ul>
</section>
<section id="overarching-aim-1" class="slide level2">
<h2>Overarching aim</h2>
<ul>
<li class="fragment"><strong>Use the tools of probability theory to scientifically understand brains, minds, and behavior</strong></li>
<li class="fragment"><strong>New perspective</strong>. Upgrade your scientific thinking</li>
<li class="fragment"><strong>Simplicity.</strong> Tools are parsimonious, flexible, intuitive, and powerful.</li>
<li class="fragment"><strong>Universality.</strong> Same principles apply to science, statistic, brains, minds, behaviors, evolution, even physics.</li>
</ul>
</section>
<section id="specific-aims-1" class="slide level2">
<h2>Specific aims</h2>
<ul>
<li class="fragment"><strong>Focus on mind &amp; behavior</strong> â†’ Cognitive models</li>
<li class="fragment"><strong>Connect to neural data</strong> via simple methods ğŸ§ </li>
<li class="fragment"><strong>Stop describing ğŸ¥± â†’ Start explaining ğŸ˜Œ</strong></li>
<li class="fragment"><strong>Engage.</strong> Hands-on Â· Interactive Â· Discursive</li>
<li class="fragment"><strong>KISS.</strong> Keep It Simple, Stoopid ğŸ˜œ</li>
<li class="fragment"><strong>Vibes.</strong> Intuitive Â· Playful Â· Fun Â· Useful âœ¨</li>
</ul>
</section>
<section id="our-expectations-of-you-1" class="slide level2">
<h2>Our expectations of you:</h2>
<ul>
<li class="fragment"><strong>Life is short.</strong> Donâ€™t let things pass that you dont understand.</li>
<li class="fragment"><strong>Your life matters.</strong> Your understanding matters. Actively take part.</li>
<li class="fragment"><strong>You are entitled</strong> to understand this.</li>
<li class="fragment"><strong>Donâ€™t listen</strong> to it, fight it. ğŸ¥Š</li>
<li class="fragment"><strong>Disrupt.</strong> Ask questions, interrupt. ğŸ™‹â€â™‚ï¸</li>
<li class="fragment"><strong>Be sceptical.</strong> The truth is out there. ğŸ¤¨</li>
</ul>
</section>
<section id="we-love-to-hear" class="slide level2">
<h2>We love to hear:</h2>
<ul>
<li class="fragment"><em>â€œIâ€™m probably being stupidâ€¦â€</em> ğŸ¤ª</li>
<li class="fragment"><em>â€œI might have missed thisâ€¦â€</em></li>
<li class="fragment"><em>â€œi dont understand whyâ€¦â€</em></li>
<li class="fragment"><em>â€œdo you have an intuition for whyâ€¦â€</em></li>
<li class="fragment"><em>â€œiâ€™m confusedâ€¦â€</em> ğŸ¤”</li>
</ul>
</section>
<section id="dont-do-this-to-yourself" class="slide level2">
<h2>Donâ€™t do this to yourself:</h2>
<ul>
<li class="fragment">Nod and pretend you get something ğŸ™…â€â™‚ï¸</li>
<li class="fragment">Assume you are the only one confused ğŸ˜µâ€ğŸ’«ğŸ˜µ</li>
<li class="fragment">Collapse under self doubt.</li>
</ul>
</section>
<section id="course-team" class="slide level2">
<h2>Course team</h2>
<ul>
<li class="fragment">Too shy to ask a question, talk to Janine</li>
<li class="fragment">Organisation, ask David or Ollie</li>
<li class="fragment">Technical issue / Github / Binder / Python &gt; Simon</li>
</ul>
</section>
<section id="upcoming-lectures-mon-and-tues" class="slide level2">
<h2>Upcoming lectures (Mon and Tues)</h2>
<ul>
<li class="fragment">Basics of Bayes</li>
<li class="fragment">Modelling cognition as a binary process</li>
<li class="fragment">Modeling mixtures of cognitive processes</li>
<li class="fragment">Selecting models</li>
<li class="fragment">Quantifying evidence</li>
<li class="fragment">Posterior odds <!-- #endregion--></li>
</ul>
<!-- #region Lecture#2 Basics of Bayesian analysis-->
</section></section>
<section>
<section id="lecture-2-basics-of-bayesian-analysis" class="title-slide slide level1 center">
<h1>Lecture 2: Basics of Bayesian Analysis</h1>
<ul>
<li class="fragment"><br></li>
<li class="fragment"><strong>Roadmap</strong></li>
<li class="fragment">The spirit of Bayesian thinking</li>
<li class="fragment">What is Bayesian modeling?</li>
<li class="fragment">Principles of Bayesian inference</li>
<li class="fragment">Observable vs.&nbsp;latent variables</li>
<li class="fragment">Beliefs and evidence</li>
<li class="fragment">Estimation methods</li>
<li class="fragment">Why Bayesian methods?</li>
</ul>
</section>
<section id="the-spirit-of-bayesian-thinking" class="slide level2">
<h2>The spirit of Bayesian thinking</h2>
<ul>
<li class="fragment"><br></li>
<li class="fragment"><em>â€œProbability theory is nothing but common sense reduced to calculation.â€</em> â€” Laplace (1814)<br>
</li>
<li class="fragment"><br></li>
<li class="fragment"><em>â€œThe rules of probability are the rules of consistent reasoning.â€</em> â€” Jaynes (2003)<br>
</li>
<li class="fragment"><br></li>
<li class="fragment"><em>â€œBayesian methods are not a special brand of inference; they are the only logically consistent rules for inference that are known.â€</em> â€” Jaynes (2003)</li>
</ul>
<div class="footer">
<p>Laplace (1814); Jaynes (2003)</p>
</div>
</section>
<section id="bayesianism-as-the-calculus-of-common-sense" class="slide level2">
<h2>Bayesianism as the calculus of common sense</h2>
<ul>
<li class="fragment"><br><br></li>
<li class="fragment"><em>Bayesianism is just probability theory applied to inference.</em> â€” Jaynes (2003)</li>
</ul>
<div class="footer">
<p>Jaynes (2003)</p>
</div>
</section>
<section id="probability-as-rational-consistency" class="slide level2">
<h2>Probability as rational consistency</h2>
<ul>
<li class="fragment">Bayesian modeling follows the rules of probability.</li>
<li class="fragment">Probability is logic.</li>
<li class="fragment">Logic is consistency.</li>
<li class="fragment">Consistency is rationality.</li>
<li class="fragment">And rationality is just thinking clearly.</li>
</ul>
</section>
<section id="so-what-is-bayesian-modeling-of-minds-brains-and-behavior" class="slide level2">
<h2>So what is â€œBayesian Modeling of Minds, Brains, and Behaviorâ€?</h2>
<ul>
<li class="fragment">This course is about <strong>thinking clearly about minds, brains, and behavior</strong>.</li>
<li class="fragment">Itâ€™s about testing theories rationally, using the evidence provided by data.</li>
<li class="fragment">Bayesian modeling offers a principled, rational way to update beliefs based on evidence.</li>
<li class="fragment">Ta-da!</li>
</ul>
</section>
<section id="bayesian-updating-in-a-nutshell" class="slide level2">
<h2>Bayesian Updating in a Nutshell</h2>
<ul>
<li class="fragment">Prior belief â†’ Evidence â†’ Posterior belief</li>
</ul>
</section>
<section id="example-of-a-cognitive-task" class="slide level2">
<h2>Example of a cognitive task</h2>
<ul>
<li class="fragment">e.g., go/no-go</li>
<li class="fragment"><img src="/images/gonogo.png" width="800px"></li>
</ul>
</section>
<section id="cognitive-task-example" class="slide level2">
<h2>Cognitive task example</h2>
<ul>
<li class="fragment">10 binary trials of equal difficulty</li>
<li class="fragment">Estimate ability <span class="math inline">\(\theta\)</span> from behavior</li>
<li class="fragment"><span class="math inline">\(\theta\)</span> is <em>latent</em>;</li>
<li class="fragment">data are <em>observed</em></li>
<li class="fragment">e.g., correct responses <span class="math inline">\(k = 8\)</span> out of <span class="math inline">\(n = 10\)</span></li>
</ul>
</section>
<section id="latent-vs.-observed" class="slide level2">
<h2>Latent vs.&nbsp;observed</h2>
<ul>
<li class="fragment"><img src="/images/latent_observable.png" width="1000px"></li>
</ul>
</section>
<section id="why-latent-variables" class="slide level2">
<h2>Why latent variables?</h2>
<ul>
<li class="fragment">We want to explain, not just describe</li>
<li class="fragment"><em>Descriptive</em>: e.g.&nbsp;â€œWhat did the subject score?â€</li>
<li class="fragment"><em>Explanatory</em>: e.g.&nbsp;â€œWhat ability caused that score?â€</li>
</ul>
</section>
<section id="why-science-cares-about-the-latent" class="slide level2">
<h2>Why Science Cares About the Latent</h2>
<ul>
<li class="fragment">Scientific questions are causal:
<ul>
<li class="fragment">Do parkinsons patients differ in <em>risk taking</em> on and off medication?</li>
<li class="fragment">Does serotonin change <em>empathy</em>?</li>
<li class="fragment">Does alpha waves cause <em>memory consolidation</em>?</li>
<li class="fragment">Does ozempic improve <em>cognitive flexibility</em>?</li>
</ul></li>
<li class="fragment">We observe data, but we infer about latent causes</li>
<li class="fragment">Bayesian modeling connects observables to latent processes</li>
</ul>
</section>
<section id="back-to-the-cogntive-task" class="slide level2">
<h2>Back to the cogntive task</h2>
<ul>
<li class="fragment"><strong>Observed</strong>: number correct (<span class="math inline">\(k/n\)</span>)</li>
<li class="fragment"><strong>Latent</strong>: ability (<span class="math inline">\(\theta\)</span>)</li>
<li class="fragment">Same <span class="math inline">\(\theta\)</span> can result in different <span class="math inline">\(k/n\)</span></li>
<li class="fragment">Different <span class="math inline">\(\theta\)</span> can result in the same <span class="math inline">\(k/n\)</span></li>
<li class="fragment">Bayesian inference accounts for this uncertainty</li>
</ul>
</section>
<section id="beliefs-as-distributions" class="slide level2">
<h2>Beliefs as Distributions</h2>
<ul>
<li class="fragment">Probability distributions encode <strong>beliefs</strong></li>
<li class="fragment">The <strong>center</strong> = most likely value</li>
<li class="fragment">The <strong>spread</strong> = uncertainty</li>
<li class="fragment"><em>To play with this open the notebook on Binder</em></li>
<li class="fragment"><code>notebooks/probability_distributions.ipynb</code></li>
<li class="fragment">see â€œBeliefs as distributionsâ€</li>
</ul>
</section>
<section id="probability-mass-functions-for-discrete-variables" class="slide level2">
<h2>Probability mass functions for discrete variables</h2>
<ul>
<li class="fragment"><img src="/images/probability_mass.jpg" width="350px" style="display:inline"></li>
<li class="fragment">Total mass sums to 1: <span class="math inline">\(\sum_x p(x) = 1\)</span><br>
</li>
<li class="fragment">Range sums: <span class="math inline">\(p(2 \leq x \leq 4) = 0.4\)</span><br>
</li>
<li class="fragment">Odds: <span class="math inline">\(\frac{p(5)}{p(7)} = 7\)</span></li>
</ul>
</section>
<section id="probaility-density-functions-for-continuous-variables" class="slide level2">
<h2>Probaility density functions for continuous variables</h2>
<ul>
<li class="fragment"><img src="/images/probability_density.jpg" width="350px"></li>
<li class="fragment">all probability density integrates to 1</li>
<li class="fragment">area under the curve is 1</li>
<li class="fragment">densities can exceed 1</li>
<li class="fragment">ratios make sense: 5.5 is 5 times less likely than 0.7</li>
</ul>
</section>
<section id="probability-density-functions-for-continuous-variables" class="slide level2">
<h2>Probability Density Functions for continuous variables</h2>
<ul>
<li class="fragment"><img src="/images/probability_density.jpg" width="350px" style="display:inline"></li>
<li class="fragment">Total area under curve: <span class="math inline">\(\int p(x)\,dx = 1\)</span><br>
</li>
<li class="fragment">Densities can &gt; 1, but only area matters.<br>
</li>
<li class="fragment">Likelihood ratios make sense: e.g., <span class="math inline">\(p(5.5)/p(0.7) = 1/5\)</span></li>
</ul>
</section>
<section id="interpreting-probability-distributions" class="slide level2">
<h2>Interpreting probability distributions</h2>
<ul>
<li class="fragment">Itâ€™s important to read and reason with probabilty distributions.</li>
<li class="fragment"><code>notebooks/probability_distributions.ipynb</code></li>
<li class="fragment">see â€œInterpreting probability distributionsâ€</li>
</ul>
</section>
<section id="bayes-rule" class="slide level2">
<h2>Bayesâ€™ rule</h2>
<ul>
<li class="fragment"><br></li>
<li class="fragment"><span class="math inline">\(p(\theta \mid D) = \frac{\color{red}{p(D \mid \theta)} \cdot \color{blue}{p(\theta)}}{\color{green}{p(D)}}\)</span></li>
<li class="fragment"><br></li>
<li class="fragment">Posterior = <span class="math inline">\(\frac{\color{red}{\text{Likelihood}}  \cdot \color{blue}{\text{Prior}}}{\color{green}{\text{Marginal likelihood}}}\)</span></li>
<li class="fragment"><br></li>
<li class="fragment"><span class="math inline">\(\theta\)</span> is a parameter, here â€œabilityâ€</li>
<li class="fragment"><span class="math inline">\(D\)</span> is data, here it is the correct performance, <span class="math inline">\(k\)</span> successes out of <span class="math inline">\(n\)</span> trials</li>
<li class="fragment"><br></li>
<li class="fragment">This tells us how our beliefs about ability are updated by the evidence provided by the data.</li>
</ul>
</section>
<section id="prior" class="slide level2">
<h2>Prior</h2>
<ul>
<li class="fragment"><span class="math inline">\(p(\theta \mid D) = \frac{\color{red}{p(D \mid \theta)} \cdot \color{blue}{p(\theta)}}{\color{green}{p(D)}}\)</span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="math inline">\(\text{Posterior} = \frac{\color{red}{\text{Likelihood}} \cdot \color{blue}{\text{Prior}}}{\color{green}{\text{Marginal likelihood}}}\)</span></li>
<li class="fragment"><br></li>
<li class="fragment"><strong><span class="math inline">\(\color{blue}{\text{Prior}}\)</span></strong> is what we believe about <span class="math inline">\(\theta\)</span> before seeing the data.</li>
<li class="fragment">It reflects our assumptions or prior knowledge.</li>
</ul>
</section>
<section id="likelihood" class="slide level2">
<h2>Likelihood</h2>
<ul>
<li class="fragment"><span class="math inline">\(p(\theta \mid D) = \frac{\color{red}{p(D \mid \theta)} \cdot \color{blue}{p(\theta)}}{\color{green}{p(D)}}\)</span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="math inline">\(\text{Posterior} = \frac{\color{red}{\text{Likelihood}} \cdot \color{blue}{\text{Prior}}}{\color{green}{\text{Marginal likelihood}}}\)</span></li>
<li class="fragment"><strong><span class="math inline">\(\color{red}{\text{Likelihood}}\)</span></strong> is the probability of data <span class="math inline">\(D\)</span> given a value of <span class="math inline">\(\theta\)</span>.</li>
<li class="fragment">It shows how well each <span class="math inline">\(\theta\)</span> explains the data.</li>
<li class="fragment">Higher likelihood â†’ stronger belief in <span class="math inline">\(\theta\)</span></li>
<li class="fragment">Lower likelihood â†’ weaker belief.</li>
</ul>
</section>
<section id="marginal-likelihood" class="slide level2">
<h2>Marginal likelihood</h2>
<ul>
<li class="fragment"><span class="math inline">\(p(\theta \mid D) = \frac{\color{red}{p(D \mid \theta)} \cdot \color{blue}{p(\theta)}}{\color{green}{p(D)}}\)</span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="math inline">\(\text{Posterior} = \frac{\color{red}{\text{Likelihood}} \cdot \color{blue}{\text{Prior}}}{\color{green}{\text{Marginal likelihood}}}\)</span></li>
<li class="fragment"><br></li>
<li class="fragment"><strong><span class="math inline">\(\color{green}{\text{Marginal likelihood}}\)</span></strong> is the total probability of the data under all possible values of <span class="math inline">\(\theta\)</span>.</li>
<li class="fragment">It represents how good the model is at predicting the data.</li>
<li class="fragment">In doing so it normalizes the result so the posterior is a valid probability distribution.</li>
<li class="fragment">Note that it is independent of <span class="math inline">\(\theta\)</span></li>
</ul>
</section>
<section id="posterior" class="slide level2">
<h2>Posterior</h2>
<ul>
<li class="fragment"><span class="math inline">\(p(\theta \mid D) = \frac{\color{red}{p(D \mid \theta)} \cdot \color{blue}{p(\theta)}}{\color{green}{p(D)}}\)</span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="math inline">\(\text{Posterior} = \frac{\color{red}{\text{Likelihood}} \cdot \color{blue}{\text{Prior}}}{\color{green}{\text{Marginal likelihood}}}\)</span></li>
<li class="fragment"><br></li>
<li class="fragment"><strong>Posterior</strong> is what we believe about <span class="math inline">\(\theta\)</span> <em>after</em> seeing the data.</li>
<li class="fragment">Itâ€™s the prior that has been updated by the evidence provided by the data.</li>
</ul>
</section>
<section id="updating-beliefs-with-data" class="slide level2">
<h2>Updating beliefs with data</h2>
<ul>
<li class="fragment">We start with a <strong>prior</strong> belief <span class="math inline">\(p(\theta)\)</span></li>
<li class="fragment">Observe <strong>data</strong>: e.g.&nbsp;( k = 9 ) correct out of ( n = 10 )</li>
<li class="fragment">Bayes updates the belief:</li>
<li class="fragment"><span class="math inline">\(p(\theta \mid D) = \frac{\color{red}{p(D \mid \theta)} \cdot \color{blue}{p(\theta)}}{\color{green}{p(D)}}\)</span></li>
</ul>
</section>
<section id="intuition-behind-belief-updating" class="slide level2">
<h2>Intuition behind belief updating</h2>
<ul>
<li class="fragment">The more likely the data is for a given <span class="math inline">\(\theta\)</span><br>
</li>
<li class="fragment">The more we believe in that value of <span class="math inline">\(\theta\)</span> after seeing the data.</li>
<li class="fragment">The values of <span class="math inline">\(\theta\)</span> that are better supported by the data, are more believed in after experiencing the data</li>
<li class="fragment">We have updated our beliefs according to the data</li>
</ul>
</section>
<section id="proportional-form-of-bayes-rule" class="slide level2">
<h2>Proportional form of Bayes rule</h2>
<ul>
<li class="fragment">Since:<br>
<span class="math inline">\(p(\theta \mid D) = \frac{\color{red}{p(D \mid \theta)} \cdot \color{blue}{p(\theta)}}{\color{green}{p(D)}}\)</span></li>
<li class="fragment"><br></li>
<li class="fragment">The <strong><span class="math inline">\(\color{green}{\text{Marginal likelihood}}\)</span></strong> <span class="math inline">\(\color{green}{p(D)}\)</span> doesnâ€™t depend on <span class="math inline">\(\theta\)</span></li>
<li class="fragment"><br></li>
<li class="fragment">So we can rewrite as:<br>
</li>
<li class="fragment"><span class="math inline">\(p(\theta \mid D) \propto \color{red}{p(D \mid \theta)} \cdot \color{blue}{p(\theta)}\)</span></li>
<li class="fragment"><span class="math inline">\(\text{Posterior} \propto \color{red}{\text{Likelihood}} \cdot \color{blue}{\text{Prior}}\)</span></li>
<li class="fragment">â€œ<em>Posterior is proportional to likelihood times prior</em>â€â€</li>
</ul>
</section>
<section id="prior-beliefs-for-theta" class="slide level2">
<h2>Prior beliefs for theta</h2>
<ul>
<li class="fragment"><code>notebooks/probability distributions.ipynb</code></li>
<li class="fragment">see â€œPrior beliefs for thetaâ€</li>
</ul>
</section>
<section id="multiplying-prior-and-likelihood" class="slide level2">
<h2>Multiplying prior and likelihood</h2>
<ul>
<li class="fragment"><code>notebooks/probability distributions.ipynb</code></li>
<li class="fragment">see â€œMultiplying prior and likelihoodâ€</li>
</ul>
</section>
<section id="is-the-likelihood-a-probability-distribution" class="slide level2">
<h2>Is the likelihood a probability distribution?</h2>
<ul>
<li class="fragment"><code>notebooks/probability distributions.ipynb</code></li>
<li class="fragment">see â€œIs the likelihood a probability distribution?â€</li>
</ul>
</section>
<section id="bayesian-credibility-intervals" class="slide level2">
<h2>Bayesian credibility intervals</h2>
<ul>
<li class="fragment"><code>notebooks/probability distributions.ipynb</code></li>
<li class="fragment">see â€œBayesian credibility intervalsâ€</li>
</ul>
</section>
<section id="summarising-the-posterior" class="slide level2">
<h2>Summarising the posterior</h2>
<ul>
<li class="fragment"><code>notebooks/probability distributions.ipynb</code></li>
<li class="fragment">see â€œSummarising the posteriorâ€</li>
</ul>
</section>
<section id="compute-the-posterior-for-the-beta" class="slide level2">
<h2>Compute the posterior for the beta</h2>
<ul>
<li class="fragment">Prior: <span class="math inline">\(p(\theta) \sim \text{Beta}(1,1)\)</span></li>
<li class="fragment">Posterior: <span class="math inline">\(p(\theta \mid D) \sim \text{Beta}(1 + k, 1 + n - k)\)</span></li>
<li class="fragment"><span class="math inline">\(k\)</span> = correct, <span class="math inline">\(n\)</span> = total trials</li>
<li class="fragment">Simple, tractable update rule for binary outcomes</li>
<li class="fragment"><code>notebooks/probability distributions.ipynb</code></li>
<li class="fragment">see â€œComputing posterior for the betaâ€</li>
</ul>
</section>
<section id="sequential-updating-of-posterior" class="slide level2">
<h2>Sequential updating of posterior</h2>
<ul>
<li class="fragment">Bayesian inference is consistent across steps</li>
<li class="fragment">One-step:
<ul>
<li class="fragment">Prior â†’ Combined data â†’ Posterior</li>
</ul></li>
<li class="fragment">Two-step:
<ul>
<li class="fragment">Prior â†’ Data1 â†’ Intermediate Posterior â†’ Data2 â†’ Final Posterior</li>
</ul></li>
<li class="fragment">Final result is identical</li>
<li class="fragment"><code>notebooks/probability distributions.ipynb</code></li>
<li class="fragment">see â€œSequential updatingâ€</li>
</ul>
</section>
<section id="why-sequential-updating-of-posterior-matters" class="slide level2">
<h2>Why sequential updating of posterior matters</h2>
<ul>
<li class="fragment">You can peak at your data, itâ€™s ok!</li>
<li class="fragment">Enables inference as data rolls in.</li>
<li class="fragment"><em>Optional stopping</em>: stop early, or extend data collection</li>
<li class="fragment"><em>Efficient</em>: time, money, resources</li>
<li class="fragment"><em>Ethical</em>: minimises animals, humans, unnecessary treatment etc.</li>
</ul>
</section>
<section id="frequentist-methods-dont-allow-this" class="slide level2">
<h2>Frequentist methods donâ€™t allow this</h2>
<ul>
<li class="fragment">Frequentist inference assumes a fixed sample size and plan</li>
<li class="fragment">Stopping early or collecting more data invalidates p-values</li>
<li class="fragment">Counterfactual policies: what you would have done, if the data had turned out different impacts on your p-values.</li>
<li class="fragment">Not widely understood.</li>
</ul>
</section>
<section id="conjugate-priors" class="slide level2">
<h2>Conjugate priors</h2>
<ul>
<li class="fragment">If Prior and posterior from the same distribution family â†’ <em>conjugate</em><br>
</li>
<li class="fragment"><br></li>
<li class="fragment">For example:</li>
<li class="fragment"><span class="math inline">\(p(\theta): \text{Beta}(\alpha, \beta)\)</span></li>
<li class="fragment"><span class="math inline">\(p(\theta|data): \text{Beta}(\alpha + k, \beta + n - k)\)</span></li>
<li class="fragment"><br></li>
<li class="fragment">The posterior can be computed by plugging data directly into an equation</li>
<li class="fragment">Conjugacy allows for <em>analytic updates</em></li>
</ul>
</section>
<section id="when-conjugacy-isnt-possible-sampling" class="slide level2">
<h2>When conjugacy isnt possible: Sampling</h2>
<ul>
<li class="fragment">Conjugacy is relatively rare in real world cases</li>
<li class="fragment">In cases where conjugacy is not available sampling solutions are possible</li>
<li class="fragment">Commonly MCMC - Markov Chain Monte Carlo</li>
<li class="fragment">Works even when no closed-form solution</li>
<li class="fragment">Approximates the posterior via sampling</li>
</ul>
</section>
<section id="analytic-vs.-sampling" class="slide level2">
<h2>Analytic vs.&nbsp;Sampling</h2>
<ul>
<li class="fragment"><strong>Analytic</strong>: Exact, when conjugate, rare</li>
<li class="fragment"><strong>MCMC</strong>: Approximate, more flexible, common</li>
</ul>
</section>
<section id="mcmc-in-practice" class="slide level2">
<h2>MCMC in Practice</h2>
<ul>
<li class="fragment"><strong>Red pill</strong>: Learn how MCMC really works ğŸ¤“
<ul>
<li class="fragment"><a href="https://chat.openai.com/share/887b4e2d-2689-4e2d-b9ae-246b71d5782e">Intuitive guide to MCMC internals</a><br>
</li>
<li class="fragment"><a href="https://chat.openai.com/share/55cb6a00-1718-4327-8d51-3902a2064a11">Metropolis-Hastings explained simply</a><br>
</li>
<li class="fragment">These methods will keep evolving â€” expect newer algorithms, faster sampling, and better approximations.</li>
</ul></li>
<li class="fragment"><strong>Blue pill</strong>: Trust the method and use it (but know how to spot when itâ€™s broken) ğŸ˜„
<ul>
<li class="fragment">Weâ€™ll demonstrate and visualise MCMC in practice.</li>
</ul></li>
</ul>
</section>
<section id="mcmc-demo" class="slide level2">
<h2>MCMC demo</h2>
<ul>
<li class="fragment">Go to â€œMCMCâ€</li>
<li class="fragment"><code>notebooks/probability distributions.ipynb</code></li>
</ul>
</section>
<section id="why-bayesian-methods" class="slide level2">
<h2>Why Bayesian Methods?</h2>
<ul>
<li class="fragment"><strong>Principled reasoning</strong>: Probabilistic logic = consistent thinking<br>
</li>
<li class="fragment"><strong>Uncertainty-aware</strong>: Fully models uncertainty<br>
</li>
<li class="fragment"><strong>Latent variables</strong>: Model hidden causes, not just outcomes<br>
</li>
<li class="fragment"><strong>Transparent updating</strong>: Prior â†’ Evidence â†’ Posterior</li>
<li class="fragment"><strong>Sequential updating</strong>: Updating is the same whether data is sequential or all-in-one-go.<br>
</li>
<li class="fragment"><strong>Richer explanations</strong>: From describing data to explaining via theory<br>
</li>
<li class="fragment"><strong>Flexible models</strong>: Hierarchical, generative, extensible</li>
<li class="fragment"><strong>Simple</strong>: Same principle always. Learn it once. Apply it forever.</li>
</ul>
<!-- #endregion-->
<!-- #region Lecture#3 Modelling a binary process-->
</section></section>
<section>
<section id="modeling-a-binary-process" class="title-slide slide level1 center">
<h1>Modeling a Binary Process</h1>
<ul>
<li class="fragment">Modeling binary outcomes in cognition<br>
</li>
<li class="fragment">From observed data to hidden probabilities<br>
</li>
<li class="fragment">Graphical models and their notation<br>
</li>
<li class="fragment">Bayesian inference with JAGS<br>
</li>
<li class="fragment">Convergence diagnostics and posterior checks</li>
</ul>
</section>
<section id="modeling-a-binary-process-1" class="slide level2">
<h2>Modeling a Binary Process</h2>
<ul>
<li class="fragment">Start simple: focus on binary outcomes<br>
e.g., <em>Success/Failure</em>, <em>Correct/Incorrect</em>, <em>Yes/No</em></li>
<li class="fragment">Common examples: <em>coin flips, true/false questions, detection tasks, motor responses</em></li>
<li class="fragment">In our go/no-go example, each of the <span class="math inline">\(n\)</span> trials results in either <span class="math inline">\(k\)</span> successes<br>
</li>
<li class="fragment">Binary processes are foundational for modeling cognition</li>
</ul>
</section>
<section id="getting-started" class="slide level2">
<h2>Getting Started</h2>
<ul>
<li class="fragment">Our goal is to infer ability in a go-no-go task</li>
<li class="fragment">We estimate a rate â€” the hidden probability <span class="math inline">\(\theta\)</span> that a response is correct</li>
<li class="fragment">We represent our uncertainty about <span class="math inline">\(\theta\)</span> as a probability distribution</li>
<li class="fragment">Many cognitive tasks can be modeled this way</li>
</ul>
</section>
<section id="binary-tasks-in-cognitive-science" class="slide level2">
<h2>Binary Tasks in Cognitive Science</h2>
<ul>
<li class="fragment">Go/no-go, stop-signal, 2AFC, task switching<br>
</li>
<li class="fragment">Recognition memory, Stroop, Flanker, oddball detection<br>
</li>
<li class="fragment">Visual search, discrimination tasks, and so on.</li>
</ul>
</section>
<section id="from-binary-outcomes-to-a-hidden-rate" class="slide level2">
<h2>From Binary Outcomes to a Hidden Rate</h2>
<ul>
<li class="fragment">Observe <span class="math inline">\(k\)</span> successes in <span class="math inline">\(n\)</span> trials â†’ compute <span class="math inline">\(\frac{k}{n}\)</span></li>
<li class="fragment">But our interest is in the <em>underlying</em> success rate <span class="math inline">\(\theta\)</span></li>
<li class="fragment">Model: <span class="math inline">\(k \sim \text{Binomial}(\theta, n)\)</span></li>
<li class="fragment"><span class="math inline">\(p(k \mid \theta, n) = \binom{n}{k} \theta^k (1 - \theta)^{n - k}\)</span></li>
<li class="fragment">Assumes independent, identically distributed (i.i.d.) trials â€” no history effects</li>
</ul>
</section>
<section id="try-it-yourself" class="slide level2">
<h2>Try it Yourself</h2>
<ul>
<li class="fragment"><code>notebooks/probability distributions.ipynb</code></li>
<li class="fragment">see lecture 3 &gt; â€œBinomial distributionâ€</li>
</ul>
</section>
<section id="graphical-models" class="slide level2">
<h2>Graphical Models</h2>
<ul>
<li class="fragment">Graphical models represent probabilistic structure visually</li>
<li class="fragment">Nodes represent variables; edges represent dependencies</li>
<li class="fragment">Child nodes are conditionally dependent on parent nodes</li>
<li class="fragment">This is our JAGS model:</li>
<li class="fragment"><img data-src="images/graphical%20model.png" style="width:30.0%"></li>
</ul>
</section>
<section id="graphical-notation" class="slide level2">
<h2>Graphical Notation</h2>
<ul>
<li class="fragment"><p><strong>Circular</strong> nodes: continuous variables<br>
</p></li>
<li class="fragment"><p><strong>Square</strong> nodes: discrete variables</p></li>
<li class="fragment"><p><strong>Shaded</strong> nodes: observed<br>
</p></li>
<li class="fragment"><p><strong>Unshaded</strong> nodes: hidden</p></li>
<li class="fragment"><p><strong>Single border</strong>: stochastic variable<br>
</p></li>
<li class="fragment"><p><strong>Double border</strong>: deterministic relationship</p></li>
</ul>
</section>
<section id="graphical-notation-reference" class="slide level2">
<h2>Graphical Notation Reference</h2>
<ul>
<li class="fragment"><img data-src="images/graphical%20lexicon.jpeg" style="width:70.0%"></li>
</ul>
</section>
<section id="graphical-model-quiz" class="slide level2">
<h2>Graphical Model Quiz</h2>
<ul>
<li class="fragment"><img data-src="images/graphical%20model%20test.jpeg" style="width:30.0%"></li>
<li class="fragment">Upper node: What type of variable is this?<br>
</li>
<li class="fragment"><strong>Answer:</strong> Continuous, stochastic, and observed</li>
<li class="fragment">Lower node: What type of variable is this?<br>
</li>
<li class="fragment"><strong>Answer:</strong> Discrete, deterministic, and unobserved</li>
</ul>
</section>
<section id="sampling-via-jags" class="slide level2">
<h2>Sampling via JAGS</h2>
<div class="sourceCode" id="cb4" data-code-line-numbers="0|1|2|3|4|5"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href=""></a>model {              <span class="co"># Define the model</span></span>
<span id="cb4-2"><a href=""></a>  theta <span class="op">~</span> dbeta(<span class="dv">1</span>,<span class="dv">1</span>) <span class="co"># Prior: theta follows a uniform beta distribution</span></span>
<span id="cb4-3"><a href=""></a>  k <span class="op">~</span> dbin(theta,n)  <span class="co"># Likelihood: k follows a binomial distribution</span></span>
<span id="cb4-4"><a href=""></a>                     <span class="co"># with parameters theta and n</span></span>
<span id="cb4-5"><a href=""></a>}                    <span class="co"># End of model</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<ul>
<li class="fragment"><img data-src="images/graphical%20model.png" style="width:30.0%"></li>
</ul>
</section>
<section id="interpreting-the-graphical-model-for-the-code" class="slide level2">
<h2>Interpreting the graphical model for the code</h2>
<ul>
<li class="fragment"><img data-src="images/graphical%20model.png" style="width:30.0%"></li>
<li class="fragment">Theta is latent, and continuous</li>
<li class="fragment">n is observed and discrete</li>
<li class="fragment">k is observed and discrete</li>
<li class="fragment">Both feed n and k feed in to the likelihood to generate k</li>
</ul>
</section>
<section id="r-hat-as-a-convergence-check" class="slide level2">
<h2>R-hat as a convergence check</h2>
<ul>
<li class="fragment">Itâ€™s important to check that the sampling has converged to the stationary distribution.</li>
<li class="fragment">One heuristic is the R-hat statistic:<br>
<span class="math inline">\(\hat{R} = \frac{\text{var}(\text{within-chain})}{\text{var}(\text{across-chain})}\)</span></li>
<li class="fragment">Rule of thumb: <span class="math inline">\(\hat{R}\)</span> should be between 1.00 and 1.01 for convergence.</li>
</ul>
</section>
<section id="inspecting-the-chains" class="slide level2">
<h2>Inspecting the chains</h2>
<ul>
<li class="fragment">the chains of samples should look like <em>hairy catapillars</em></li>
<li class="fragment">like this:</li>
<li class="fragment"><img data-src="images/hairy_caterpillar.png" style="width:60.0%"></li>
</ul>
</section>
<section id="try-it-yourself-1" class="slide level2">
<h2>Try it yourself</h2>
<ul>
<li class="fragment">go to â€œMCMC convergence checks**</li>
<li class="fragment">ğŸ“‚ <code>notebooks/probability distributions.ipynb</code></li>
</ul>
</section>
<section id="difference-between-two-rates" class="slide level2">
<h2>Difference between two rates</h2>
<ul>
<li class="fragment">Suppose we observe two processes, each producing successes out of trials:</li>
<li class="fragment">Process 1: <span class="math inline">\(k_1\)</span> successes out of <span class="math inline">\(n_1\)</span> trials<br>
</li>
<li class="fragment">Process 2: <span class="math inline">\(k_2\)</span> successes out of <span class="math inline">\(n_2\)</span> trials</li>
<li class="fragment">We assume each is governed by a different underlying rate: <span class="math inline">\(\theta_1\)</span> and <span class="math inline">\(\theta_2\)</span>.</li>
</ul>
</section>
<section id="estimating-the-difference" class="slide level2">
<h2>Estimating the difference</h2>
<ul>
<li class="fragment">We want to model each rate with a posterior Beta distribution, and we are interested in the difference:</li>
<li class="fragment"><span class="math inline">\(\delta = \theta_1 - \theta_2\)</span></li>
<li class="fragment">This tells us how much more (or less) likely success is in one group compared to the other.</li>
</ul>
</section>
<section id="examples-and-intuition" class="slide level2">
<h2>Examples and intuition</h2>
<ul>
<li class="fragment">Examples:</li>
<li class="fragment">ğŸ“ˆ Effect of a drug on performance (<span class="math inline">\(\theta_1\)</span> = treated, <span class="math inline">\(\theta_2\)</span> = control)</li>
<li class="fragment">ğŸ‘¶ Performance difference between age groups</li>
<li class="fragment">ğŸ§ª Comparison of two algorithms on success rate</li>
<li class="fragment">A positive <span class="math inline">\(\delta\)</span> means group 1 is better; a negative <span class="math inline">\(\delta\)</span> means group 2 is better.</li>
</ul>
</section>
<section id="graphical-model-for-inferring-differences" class="slide level2">
<h2>Graphical model for inferring differences</h2>
<ul>
<li class="fragment"><img data-src="images/fig3.3.jpg" style="width:100.0%"></li>
<li class="fragment">Why is delta double boundary?</li>
<li class="fragment">Because it is completely determined by the two thetas</li>
</ul>
</section>
<section id="jags-code-for-infferring-differences-in-rates" class="slide level2">
<h2>JAGS code for infferring differences in rates</h2>
<div class="sourceCode" id="cb5" data-code-line-numbers="0|1|2|3|4|5|6"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href=""></a>model{ </span>
<span id="cb5-2"><a href=""></a>  k1 <span class="op">~</span> dbin(theta1,n1)</span>
<span id="cb5-3"><a href=""></a>  k2 <span class="op">~</span> dbin(theta2,n2)</span>
<span id="cb5-4"><a href=""></a>  theta1 <span class="op">~</span> dbeta(<span class="dv">1</span>,<span class="dv">1</span>)</span>
<span id="cb5-5"><a href=""></a>  theta2 <span class="op">~</span> dbeta(<span class="dv">1</span>,<span class="dv">1</span>)</span>
<span id="cb5-6"><a href=""></a>  delta <span class="op">&lt;-</span>theta1<span class="op">-</span>theta2</span>
<span id="cb5-7"><a href=""></a>}                   <span class="co"># End of model</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="try-it-yourself-2" class="slide level2">
<h2>Try it yourself</h2>
<ul>
<li class="fragment">go to â€œInferring the difference between two ratesâ€<br>
</li>
<li class="fragment"><code>notebooks/probability distributions.ipynb</code></li>
</ul>
</section>
<section id="interpret-the-posterior" class="slide level2">
<h2>Interpret the posterior</h2>
<ul>
<li class="fragment">What is the approximate probability that the difference in rates (<span class="math inline">\(\delta\)</span>) is below 0?</li>
<li class="fragment"><img data-src="images/posterior_delta.png" style="width:45.0%"></li>
</ul>
</section>
<section id="inferring-a-common-rate" class="slide level2">
<h2>Inferring a common rate</h2>
<ul>
<li class="fragment">In some cases we want to infer a rate for 2 different processes</li>
<li class="fragment">e.g.&nbsp;<em>same subject &amp; task, two different sessions</em></li>
<li class="fragment">e.g.&nbsp;<em>same group, different subjects</em></li>
<li class="fragment">e.g.&nbsp;<em>same subject, different tasks</em></li>
<li class="fragment">Here we would model a single <span class="math inline">\(\theta\)</span></li>
<li class="fragment"><img data-src="./images/common_rate_model.jpg"></li>
</ul>
</section>
<section id="same-model-with-plate-notation" class="slide level2">
<h2>Same model with plate notation</h2>
<ul>
<li class="fragment"><img data-src="./images/common_rate_model_plate.jpg"></li>
<li class="fragment">note only one theta, but multiple processes indexed by i</li>
</ul>
</section>
<section id="jags-code-for-inferring-a-common-rate" class="slide level2">
<h2>JAGS code for inferring a common rate</h2>
<div class="sourceCode" id="cb6" data-code-line-numbers="0|1|2|3|4"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href=""></a> model{ </span>
<span id="cb6-2"><a href=""></a>  k1 <span class="op">~</span> dbin(theta,n1)</span>
<span id="cb6-3"><a href=""></a>  k2 <span class="op">~</span> dbin(theta,n2)</span>
<span id="cb6-4"><a href=""></a>  theta <span class="op">~</span> dbeta(<span class="dv">1</span>,<span class="dv">1</span>)</span>
<span id="cb6-5"><a href=""></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<ul>
<li class="fragment"><img data-src="./images/common_rate_model.jpg" style="width:100.0%"></li>
<li class="fragment">Only one <span class="math inline">\(\theta\)</span> is modelling the two sets of data <span class="math inline">\(k1\)</span> and <span class="math inline">\(k2\)</span></li>
</ul>
</section>
<section id="try-it-out" class="slide level2">
<h2>Try it out</h2>
<ul>
<li class="fragment">go to â€œInferring a common rateâ€<br>
</li>
<li class="fragment"><code>notebooks/probability distributions.ipynb</code></li>
</ul>
</section>
<section id="predictions" class="slide level2">
<h2>Predictions</h2>
<ul>
<li class="fragment">In Bayesian modeling, everything is about prediction.</li>
<li class="fragment">There are two fundamental axes:
<ol type="1">
<li class="fragment">Are we predicting <strong>parameters</strong> or <strong>data</strong>?</li>
<li class="fragment">Are we predicting <strong>before</strong> or <strong>after</strong> observing data?</li>
</ol></li>
</ul>
</section>
<section id="diiferent-types-of-prediction" class="slide level2">
<h2>Diiferent types of prediction</h2>
<table class="caption-top">
<colgroup>
<col style="width: 14%">
<col style="width: 36%">
<col style="width: 48%">
</colgroup>
<thead>
<tr class="header">
<th></th>
<th><strong>Before data</strong></th>
<th><strong>After data</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Parameters</strong></td>
<td>Prior distribution: <span class="math inline">\(p(\theta)\)</span></td>
<td>Posterior distribution: <span class="math inline">\(p(\theta \mid d_{\text{obs}})\)</span></td>
</tr>
<tr class="even">
<td><strong>Data</strong></td>
<td>Prior predictive distribution: <span class="math inline">\(p(d_{\text{new}})\)</span></td>
<td>Posterior predictive distribution: <span class="math inline">\(p(d_{\text{new}} \mid d_{\text{obs}})\)</span></td>
</tr>
</tbody>
</table>
</section>
<section id="predicting-parameters" class="slide level2">
<h2>Predicting parameters</h2>
<ul>
<li class="fragment">The <strong>prior distribution</strong> <span class="math inline">\(p(\theta)\)</span> is our prediction about the parameter before seeing data.</li>
<li class="fragment">The <strong>posterior distribution</strong> <span class="math inline">\(p(\theta \mid d_\text{obs})\)</span> is our updated prediction after observing data.</li>
</ul>
</section>
<section id="predicting-data." class="slide level2">
<h2>Predicting data.</h2>
<ul>
<li class="fragment">The <strong>prior predictive distribution</strong> <span class="math inline">\(p(d_{\text{new}})\)</span> tells us what data we expect based on our prior belief about <span class="math inline">\(\theta\)</span>.</li>
<li class="fragment">The <strong>posterior predictive distribution</strong> <span class="math inline">\(p(d_{\text{new}} \mid d_{\text{obs}})\)</span> predicts new data based on our updated belief.</li>
</ul>
</section>
<section id="todays-posterior-is-tomorrows-prior" class="slide level2">
<h2>Todays posterior is tomorrows prior</h2>
<ul>
<li class="fragment">This measn that any posterior can always become a prior for a future prediction, and so on.</li>
</ul>
</section>
<section id="prior-and-posterior-prediction" class="slide level2">
<h2>Prior and posterior prediction</h2>
<div class="sourceCode" id="cb7" data-code-line-numbers="1-3|5-6|8-10|12-13"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href=""></a>model {</span>
<span id="cb7-2"><a href=""></a>  <span class="co"># Prior distribution</span></span>
<span id="cb7-3"><a href=""></a>  thetaprior <span class="op">~</span> dbeta(<span class="dv">1</span>,<span class="dv">1</span>) </span>
<span id="cb7-4"><a href=""></a>  </span>
<span id="cb7-5"><a href=""></a>  <span class="co"># Prior predictive distribtion</span></span>
<span id="cb7-6"><a href=""></a>  priorpredk <span class="op">~</span> dbin(thetapior,n) </span>
<span id="cb7-7"><a href=""></a>  </span>
<span id="cb7-8"><a href=""></a>  <span class="co"># Posterior distribution </span></span>
<span id="cb7-9"><a href=""></a>  theta <span class="op">~</span> dbeta(<span class="dv">1</span>,<span class="dv">1</span>) <span class="co"># theta becomes the posterior distribution of   </span></span>
<span id="cb7-10"><a href=""></a>  k <span class="op">~</span> dbin(theta,n) <span class="co">#likelihood for updating prior to posterior</span></span>
<span id="cb7-11"><a href=""></a>  </span>
<span id="cb7-12"><a href=""></a>  <span class="co"># Posterior predictive distribution</span></span>
<span id="cb7-13"><a href=""></a>  postpredk <span class="op">~</span> dbin(theta,n) <span class="co"># posterior predictive distibution</span></span>
<span id="cb7-14"><a href=""></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="samples-of-the-four-distributions" class="slide level2">
<h2>Samples of the four distributions</h2>
<ul>
<li class="fragment"><img data-src="./images/prior_post_predictions.jpg" style="width:60.0%"></li>
<li class="fragment">Prior and posterior distributions are in the space of the parameter</li>
<li class="fragment">Prior and posterior predictive distributions are in space of the data k out of n trials.</li>
</ul>
</section>
<section id="comparing-data-to-the-posterior-predictive-distribution" class="slide level2">
<h2>Comparing data to the posterior predictive distribution</h2>
<ul>
<li class="fragment"><ul>
<li class="fragment"><img data-src="./images/common_rate_model.jpg" style="width:100.0%"></li>
</ul></li>
<li class="fragment">If we estimate the model along with its predictive distributions</li>
<li class="fragment">We can see how this compares to the actual data</li>
</ul>
</section>
<section id="descriptive-adequacy" class="slide level2">
<h2>Descriptive adequacy</h2>
<ul>
<li class="fragment">â€¦means how well does the model describe the data</li>
<li class="fragment">Posterior for this data: k1 = 0, n1 =10 &amp; k2=10, n2 = 10</li>
<li class="fragment"><img data-src="images/posterior_common.jpg" style="width:50.0%"></li>
<li class="fragment">Looks ok, but does it have descriptive adequacy?</li>
</ul>
</section>
<section id="check-posterior-predictive-distribution-against-data" class="slide level2">
<h2>Check posterior predictive distribution against data</h2>
<ul>
<li class="fragment"><img data-src="images/posterior_predictive_common.jpg" style="width:40.0%"></li>
<li class="fragment">The model has poor <em>descriptive adequacy</em>. Why?</li>
<li class="fragment">Its a common rate model, so it predicts the same rate, but the data clearly is better modelled with different rates.</li>
</ul>
</section>
<section id="prediction-backwards-and-forward-in-time" class="slide level2">
<h2>Prediction backwards and forward in time</h2>
<ul>
<li class="fragment">Prediction normally about the future.</li>
<li class="fragment">Predictions can also apply to the past e.g.&nbsp;when information is missing.</li>
<li class="fragment">Data can help us infer hidden cognitive variables, which in turn may predict past behavior where information is incomplete.</li>
<li class="fragment">We predict what might have been known in the past if more information had been available.</li>
<li class="fragment">Inference allows prediction both forward and backward in time.</li>
</ul>
</section>
<section id="prediction-forward-and-backward-in-time" class="slide level2">
<h2>Prediction forward and backward in time</h2>
<ul>
<li class="fragment">Prediction is usually about the future â€” but it can also apply to the past.</li>
<li class="fragment">When data are missing, we use observed evidence to infer what <em>might have happened</em>.</li>
<li class="fragment">Cognitive models often predict hidden variables that explain past behavior.</li>
<li class="fragment">Inference lets us predict both what <strong>might</strong> happen and what <strong>might have</strong> happened. <!-- #endregion --></li>
</ul>
<!-- #region Lecture#4 Latent Mixture models      -->
</section></section>
<section>
<section id="latent-mixture-models" class="title-slide slide level1 center">
<h1>Latent mixture models</h1>
<ul>
<li class="fragment">What are they?</li>
<li class="fragment">How to use them to model mixtures of cognitive processes or traits</li>
<li class="fragment">How to use them to model compare models</li>
</ul>
</section>
<section id="latent-mixture-models-1" class="slide level2">
<h2>Latent mixture models</h2>
<ul>
<li class="fragment">â€¦allow you to model data as coming from a <em>mixture</em> of <em>latent</em> processes.</li>
<li class="fragment">This could be a mixture of cognitive processes, e.g.&nbsp;<em>guessing and trying, attending and not attending, remembering and forgetting.</em></li>
<li class="fragment">Or mixture of states or traits, e.g.&nbsp;<em>depresssed vs.&nbsp;healthy, parkinsons vs.&nbsp;healthy, sleepy vs.&nbsp;awake</em><br>
</li>
<li class="fragment">An indicator variable estimates which mixture of processes generated the data.</li>
<li class="fragment">You can also use these mixture models to compare different models</li>
</ul>
</section>
<section id="example-latent-mixture-model-of-cognitive-test" class="slide level2">
<h2>Example: Latent mixture model of cognitive test</h2>
<ul>
<li class="fragment"><em>â€œTryersâ€</em> have an ability that determines their rate of correct responses.</li>
<li class="fragment"><em>â€œGuessersâ€</em> score at chance level (e.g.&nbsp;50%).</li>
<li class="fragment">Each participant belongs to one of the two groups.</li>
<li class="fragment">An <em>indicator</em> variable <span class="math inline">\(z_i\)</span> models <em>guesser</em> or <em>tryer</em>.</li>
</ul>
</section>
<section id="latent-mixture-model-vs.-simpler-model" class="slide level2">
<h2>Latent mixture model vs.&nbsp;simpler model</h2>
<ul>
<li class="fragment"><img data-src="images/lmm.jpg" style="width:50.0%"></li>
<li class="fragment"><img data-src="images/%20binomial%20rate%20model.jpg" style="width:50.0%"></li>
<li class="fragment">Its the same model, <span class="math inline">\(z\)</span> just allows a mix of two different processes that can set the rate <span class="math inline">\(\theta\)</span>.</li>
<li class="fragment">Simples.</li>
</ul>
</section>
<section id="latent-mixture-graphical-model" class="slide level2">
<h2>Latent mixture graphical model</h2>
<ul>
<li class="fragment"><img data-src="images/lmm.jpg" style="width:50.0%"></li>
<li class="fragment"><span class="math inline">\(z_i\)</span> is an indicator variable for participant <span class="math inline">\(i\)</span>.</li>
<li class="fragment"><span class="math inline">\(z_i = 0\)</span> â†’ guesser; <span class="math inline">\(z_i = 1\)</span> â†’ tryer.</li>
<li class="fragment"><span class="math inline">\(\psi = 0.5\)</span> is the known chance performance level.</li>
<li class="fragment"><span class="math inline">\(\phi\)</span> is the tryerâ€™s ability (same as <span class="math inline">\(\theta\)</span>).</li>
<li class="fragment">Posterior of <span class="math inline">\(z\)</span> tells us the probability of each subject being either a guessers vs.&nbsp;a tryer.</li>
</ul>
</section>
<section id="jags-code-for-latent-mixture" class="slide level2">
<h2>JAGS code for latent mixture</h2>
<div class="sourceCode" id="cb8" data-code-line-numbers="1-3|4-5|6-8"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href=""></a>model {</span>
<span id="cb8-2"><a href=""></a>  <span class="cf">for</span> (i <span class="kw">in</span> <span class="dv">1</span>:p) {</span>
<span id="cb8-3"><a href=""></a>    z[i] <span class="op">~</span> dbern(<span class="fl">0.5</span>)</span>
<span id="cb8-4"><a href=""></a>  }</span>
<span id="cb8-5"><a href=""></a></span>
<span id="cb8-6"><a href=""></a>  psi <span class="op">&lt;-</span> <span class="fl">0.5</span></span>
<span id="cb8-7"><a href=""></a>  phi <span class="op">~</span> dbeta(<span class="dv">1</span>, <span class="dv">1</span>) I(<span class="fl">0.5</span>, <span class="dv">1</span>)</span>
<span id="cb8-8"><a href=""></a></span>
<span id="cb8-9"><a href=""></a>  <span class="cf">for</span> (i <span class="kw">in</span> <span class="dv">1</span>:p) {</span>
<span id="cb8-10"><a href=""></a>    theta[i] <span class="op">&lt;-</span> equals(z[i], <span class="dv">0</span>) <span class="op">*</span> psi <span class="op">+</span> equals(z[i], <span class="dv">1</span>) <span class="op">*</span> phi</span>
<span id="cb8-11"><a href=""></a>    k[i] <span class="op">~</span> dbin(theta[i], n)</span>
<span id="cb8-12"><a href=""></a>  }</span>
<span id="cb8-13"><a href=""></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="interactive-demo" class="slide level2">
<h2>Interactive demo</h2>
<ul>
<li class="fragment"><code>notebooks/probability distributions.ipynb</code></li>
<li class="fragment">Letâ€™s simulate data first</li>
<li class="fragment">go to â€œSimulate guessers and tryersâ€<br>
</li>
<li class="fragment"><br></li>
<li class="fragment">Then we can run inference on each subject</li>
<li class="fragment">go to â€œInfer guessers and tryersâ€</li>
</ul>
<!-- #endregion                             -->
<!-- #region Lecture#5 Model selection            -->
</section></section>
<section>
<section id="model-selection" class="title-slide slide level1 center">
<h1>Model selection</h1>
<ul>
<li class="fragment">Why we need to compare models</li>
<li class="fragment">Simplicity vs.&nbsp;complexity</li>
<li class="fragment">Marginal likelihood as a comparison tool</li>
<li class="fragment">Predictive performance and prior bets</li>
<li class="fragment">Bayesian model comparison intuition</li>
</ul>
</section>
<section id="why-compare-models" class="slide level2">
<h2>Why compare models?</h2>
<ul>
<li class="fragment">Exept for the last section, weâ€™ve mainly focused on single models</li>
<li class="fragment">Science advances by comparing competing explanations</li>
<li class="fragment">â€œThis theory is goodâ€ â†’ compared to what?</li>
<li class="fragment">We want to know which theory explains the data <em>better</em></li>
<li class="fragment">This requires comparing models</li>
</ul>
</section>
<section id="simplicity-vs.-complexity" class="slide level2">
<h2>Simplicity vs.&nbsp;complexity</h2>
<ul>
<li class="fragment">â€œExplain phenomena by the simplest hypothesis that worksâ€ â€” Ptolemy</li>
<li class="fragment">â€œAvoid unnecessary pluralityâ€ â€” Occamâ€™s razor</li>
<li class="fragment">â€œComplexity must pay for itselfâ€ â€” Hinton</li>
<li class="fragment">â€œMinimize free energyâ€ â€” Friston</li>
<li class="fragment">These ideas all reflect the same principle: balance fit and complexity</li>
</ul>
</section>
<section id="the-bayesian-solution" class="slide level2">
<h2>The Bayesian solution</h2>
<ul>
<li class="fragment">Many methods try to balance fit and complexity</li>
<li class="fragment">Bayesian methods do it naturally</li>
<li class="fragment">Bayes gives us a single number for model quality: marginal likelihood</li>
<li class="fragment">It rewards accuracyâ€¦</li>
<li class="fragment">â€¦and penalizes wasted complexity</li>
</ul>
</section>
<section id="conditioning-on-a-model" class="slide level2">
<h2>Conditioning on a model</h2>
<ul>
<li class="fragment">Bayesâ€™ rule always assumes <em>a model</em><br>
</li>
<li class="fragment">But we can easily imagine different models, with different priors or structures</li>
<li class="fragment">Science is filled with competing explanations and models after all<br>
</li>
<li class="fragment">We now ask: which model better predicts the data?<br>
</li>
<li class="fragment">This leads us to the <em>marginal likelihood</em><br>
</li>
<li class="fragment">Itâ€™s the probability of the data, <em>given the model</em></li>
</ul>
</section>
<section id="marginal-likelihood-1" class="slide level2">
<h2>Marginal likelihood</h2>
<ul>
<li class="fragment"><span class="math inline">\(p(D \mid M)\)</span> = average predictive performance of model <span class="math inline">\(M\)</span></li>
<li class="fragment">Itâ€™s a single number:</li>
<li class="fragment"><em>How well the model predicted the data, on average</em></li>
<li class="fragment">It accounts for <em>all</em> parameter values, weighted by their prior</li>
</ul>
</section>
<section id="analogy-to-betting" class="slide level2">
<h2>Analogy to betting</h2>
<ul>
<li class="fragment">Think of it like your model is betting on which parameter values best predict the data</li>
<li class="fragment">The better your bets, the higher your modelâ€™s score</li>
<li class="fragment">The prior is the placing of the bets, and the marginal likelihood is how good those bets paid off.</li>
</ul>
</section>
<section id="marginal-likelihood-in-words" class="slide level2">
<h2>Marginal likelihood in words</h2>
<ul>
<li class="fragment">How probable was the data under this model <span class="math inline">\(M\)</span>?</li>
<li class="fragment">Did the model concentrate its predictions where the data actually were?</li>
<li class="fragment">Priors spread out predictive mass</li>
<li class="fragment">Bad priors waste predictions on wrong areas</li>
<li class="fragment">Good priors focus predictions where the data land</li>
</ul>
</section>
<section id="octopus-example" class="slide level2">
<h2>Octopus example</h2>
<ul>
<li class="fragment">There are two <del>octopi</del> octopusses.</li>
<li class="fragment">Both claim to be paranormal.</li>
<li class="fragment">Itâ€™s 1970, so they are both working for the CIA</li>
<li class="fragment"><img data-src="images/octopuses.jpg" style="width:50.0%"></li>
</ul>
</section>
<section id="octopus-predictions" class="slide level2">
<h2>Octopus predictions</h2>
<ul>
<li class="fragment">Where is the Russian sub?</li>
<li class="fragment">Alice: northern hemisphere</li>
<li class="fragment">Bob: Baltic Sea</li>
<li class="fragment">Data: Off the coast of Stockholm</li>
<li class="fragment">Alice was vaguely right</li>
<li class="fragment">Bob was more precisely right â†’ higher marginal likelihood</li>
</ul>
</section>
<section id="how-is-marginal-likelihood-calculated" class="slide level2">
<h2>How is marginal likelihood calculated?</h2>
<ul>
<li class="fragment">Itâ€™s the expected likelihood under the predictions of the prior:</li>
<li class="fragment"><span class="math inline">\(p(D \mid M) = \int p(D \mid \theta, M)\, p(\theta \mid M)\, d\theta\)</span></li>
<li class="fragment">For discrete parameters:</li>
<li class="fragment"><span class="math inline">\(p(D \mid M) = \sum p(D \mid \xi_i)\, p(\xi_i)\)</span></li>
<li class="fragment">Itâ€™s a weighted average across all parameter settings</li>
</ul>
</section>
<section id="try-it-out-1" class="slide level2">
<h2>Try it out</h2>
<ul>
<li class="fragment">Lets compare alice and bob</li>
<li class="fragment"><code>notebooks/probability distributions.ipynb</code></li>
<li class="fragment">â€œCompare octopusses via marginal likelihoodâ€</li>
</ul>
</section>
<section id="worked-example" class="slide level2">
<h2>Worked example</h2>
<ul>
<li class="fragment">Suppose a model has three parameter values: <span class="math inline">\(\theta = \{0, 0.5, 1\}\)</span></li>
<li class="fragment">Prior probabilities: <span class="math inline">\(p(\theta_1) = \color{blue}{0.6}\)</span>, <span class="math inline">\(p(\theta_2) = \color{blue}{0.3}\)</span>, <span class="math inline">\(p(\theta_3) = \color{blue}{0.1}\)</span></li>
<li class="fragment">Likelihoods: <span class="math inline">\(p(D \mid \theta_1) = \color{red}{0.1}\)</span>, <span class="math inline">\(p(D \mid \theta_2) = \color{red}{0.4}\)</span>, <span class="math inline">\(p(D \mid \theta_3) = \color{red}{0.6}\)</span></li>
<li class="fragment">Marginal likelihood:<br>
<span class="math inline">\(p(D) = \color{blue}{0.6} \cdot \color{red}{0.1} + \color{blue}{0.3} \cdot \color{red}{0.4} + \color{blue}{0.1} \cdot \color{red}{0.6}\)</span></li>
<li class="fragment">Step by step:<br>
<span class="math inline">\(= \color{gray}{0.06} + \color{gray}{0.12} + \color{gray}{0.06} = \boxed{0.24}\)</span></li>
</ul>
</section>
<section id="complexity-and-spread" class="slide level2">
<h2>Complexity and spread</h2>
<ul>
<li class="fragment">More complex models spread their predictions widely</li>
<li class="fragment">This lowers the average likelihood</li>
<li class="fragment">Even if they include the truth, they may assign low probability to it</li>
<li class="fragment">Marginal likelihood punishes this</li>
<li class="fragment">Broad priors = wasted predictions = lower score = lower marginal likelihood</li>
</ul>
</section>
<section id="complexity-is-not-just-parameter-count" class="slide level2">
<h2>Complexity is not just parameter count</h2>
<ul>
<li class="fragment">A model with <em>many</em> narrow priors can be simple</li>
<li class="fragment">A model with <em>one</em> vague prior can be complex</li>
<li class="fragment">Complexity = how broadly a model spreads its predictions</li>
<li class="fragment">Narrow predictive distributions = simpler models</li>
<li class="fragment">Wide, uncertain predictions = complex models</li>
</ul>
</section>
<section id="misconception---sidenote" class="slide level2">
<h2>Misconception - sidenote</h2>
<ul>
<li class="fragment"><span style="color:gray">AIC, BIC penalize complexity by counting parameters</span><br>
</li>
<li class="fragment"><span style="color:gray">But parameter count â‰  true complexity</span><br>
</li>
<li class="fragment"><span style="color:gray">Complexity = how broadly a model spreads its predictions</span></li>
<li class="fragment"><span style="color:gray">Bayesian marginal likelihood captures this automatically</span></li>
</ul>
</section>
<section id="example-prior-vagueness" class="slide level2">
<h2>Example: prior vagueness</h2>
<ul>
<li class="fragment"><span class="math inline">\(\theta \sim \text{Uniform}(0,1)\)</span> â†’ vague â†’ complex</li>
<li class="fragment"><span class="math inline">\(\theta \sim \text{Uniform}(0.5,1)\)</span> â†’ tighter â†’ simpler</li>
<li class="fragment">Both models have one parameter</li>
<li class="fragment">But they differ in how much of the prediction space they cover</li>
<li class="fragment">Complexity depends on how much ground a model tries to cover</li>
</ul>
</section>
<section id="example-prior-vagueness-1" class="slide level2">
<h2>Example: prior vagueness</h2>
<ul>
<li class="fragment"><img data-src="images/complexity.png" style="width:100.0%"></li>
</ul>
</section>
<section id="why-marginal-likelihood-matters" class="slide level2">
<h2>Why marginal likelihood matters</h2>
<ul>
<li class="fragment">Itâ€™s the most important quantity in Bayesian model comparison</li>
<li class="fragment">It unifies inference in brain, behavior, science</li>
<li class="fragment">Maximizing it means best average predictive performance</li>
<li class="fragment">It is the quantity that arguably everything else is trying to approximate: variational Bayes, free energy minimisation, ELBO, predictive coding, predictive processing</li>
</ul>
</section>
<section id="why-marginal-likelihood-matters-1" class="slide level2">
<h2>Why marginal likelihood matters</h2>
<ul>
<li class="fragment"><span style="color:gray">Can even argue it is a <em>unique universal maximandum</em> for all physical and adaptive systems</span></li>
<li class="fragment"><span style="color:gray">Woah man, thatâ€™s like, deep.</span></li>
<li class="fragment">ğŸ˜µâ€ğŸ’«</li>
</ul>
<!-- #endregion                             -->
<!-- #region Lecture#6 Bayes factors              -->
</section></section>
<section>
<section id="the-bayes-factor" class="title-slide slide level1 center">
<h1>The Bayes factor</h1>
<ul>
<li class="fragment">Compared to what?<br>
</li>
<li class="fragment">From marginal likelihood to relative evidence<br>
</li>
<li class="fragment">Interpreting Bayes factors<br>
</li>
<li class="fragment">Worked example: guessing vs.&nbsp;non-guessing<br>
</li>
<li class="fragment">Pitfalls and philosophical notes</li>
</ul>
</section>
<section id="why-compare-models-1" class="slide level2">
<h2>Why compare models?</h2>
<ul>
<li class="fragment">A model with high marginal likelihood is good â€” but only <em>relative</em> to alternatives<br>
</li>
<li class="fragment">Absolute goodness is rarely meaningful on its own<br>
</li>
<li class="fragment">The key question is: compared to what?<br>
</li>
<li class="fragment">We want relative evidence â€” which model explains the data better<br>
</li>
<li class="fragment">The Bayes factor gives us that answer</li>
</ul>
</section>
<section id="compared-to-what" class="slide level2">
<h2>Compared to what?</h2>
<ul>
<li class="fragment"><img data-src="images/oompa.jpg" style="width:100.0%"></li>
</ul>
</section>
<section id="set-a-compared-to-what-alarm-in-your-brain" class="slide level2">
<h2>Set a compared-to-what alarm in your brain</h2>
<ul>
<li class="fragment">Listen out for one-sided superiority / inferiority claims</li>
<li class="fragment"><em>â€œthis theory explainsâ€¦â€</em></li>
<li class="fragment"><em>â€œthis model predicts the data poorlyâ€¦â€</em></li>
<li class="fragment"><em>â€œthis data is unlikely under the null hypothesisâ€¦â€</em></li>
<li class="fragment"><strong>Ding!</strong> â†’ Compared to what?</li>
</ul>
</section>
<section id="bayes-factor-definition" class="slide level2">
<h2>Bayes factor definition</h2>
<ul>
<li class="fragment">Marginal likelihood: <em>average predictive performance of a model</em><br>
</li>
<li class="fragment">Bayes factor compares this between two models<br>
</li>
<li class="fragment">Defined as the ratio of marginal likelihoods:<br>
<span class="math inline">\(BF_{\color{blue}{1} \color{red}{2}} = \frac{p(D \mid \color{blue}{M_1})}{p(D \mid \color{red}{M_2})}\)</span><br>
</li>
<li class="fragment">Quantifies how much more likely the data is under <span class="math inline">\(\color{blue}{M_1}\)</span> than <span class="math inline">\(\color{red}{M_2}\)</span></li>
</ul>
</section>
<section id="we-already-plotted-bayes-factors" class="slide level2">
<h2>We already plotted Bayes factors</h2>
<ul>
<li class="fragment">Sneakly i didnt tell you they were bayes factors.</li>
<li class="fragment"><img data-src="images/ratio_marginal_likelihoods.png"></li>
</ul>
</section>
<section id="interpreting-the-bayes-factor" class="slide level2">
<h2>Interpreting the Bayes factor</h2>
<ul>
<li class="fragment"><span class="math inline">\(BF_{12} &gt; 1\)</span> â†’ data favors <span class="math inline">\(M_1\)</span><br>
</li>
<li class="fragment"><span class="math inline">\(BF_{12} &lt; 1\)</span> â†’ data favors <span class="math inline">\(M_2\)</span><br>
</li>
<li class="fragment"><span class="math inline">\(BF_{12} = 5\)</span> â†’ data is 5Ã— more likely under <span class="math inline">\(M_1\)</span><br>
</li>
<li class="fragment"><span class="math inline">\(BF_{12} = \frac{1}{5}\)</span> â†’ data is 5Ã— more likely under <span class="math inline">\(M_2\)</span><br>
</li>
<li class="fragment">Strength of evidence depends on how far from 1 the ratio is</li>
</ul>
</section>
<section id="jeffreys-scale" class="slide level2">
<h2>Jeffreysâ€™ scale</h2>
<table class="caption-top">
<thead>
<tr class="header">
<th><span class="math inline">\(BF_{12}\)</span></th>
<th>Interpretation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>&gt;100</td>
<td>Extreme evidence for <span class="math inline">\(M_1\)</span></td>
</tr>
<tr class="even">
<td>30â€“100</td>
<td>Very strong evidence for <span class="math inline">\(M_1\)</span></td>
</tr>
<tr class="odd">
<td>10â€“30</td>
<td>Strong evidence for <span class="math inline">\(M_1\)</span></td>
</tr>
<tr class="even">
<td>3â€“10</td>
<td>Moderate evidence for <span class="math inline">\(M_1\)</span></td>
</tr>
<tr class="odd">
<td>1â€“3</td>
<td>Anecdotal evidence for <span class="math inline">\(M_1\)</span></td>
</tr>
<tr class="even">
<td>1</td>
<td>No preference</td>
</tr>
<tr class="odd">
<td>1/3â€“1</td>
<td>Anecdotal evidence for <span class="math inline">\(M_2\)</span></td>
</tr>
<tr class="even">
<td>1/10â€“1/3</td>
<td>Moderate evidence for <span class="math inline">\(M_2\)</span></td>
</tr>
<tr class="odd">
<td>1/30â€“1/10</td>
<td>Strong evidence for <span class="math inline">\(M_2\)</span></td>
</tr>
<tr class="even">
<td>1/100â€“1/30</td>
<td>Very strong evidence for <span class="math inline">\(M_2\)</span></td>
</tr>
<tr class="odd">
<td>&lt;1/100</td>
<td>Extreme evidence for <span class="math inline">\(M_2\)</span></td>
</tr>
</tbody>
</table>
</section>
<section id="try-it-out-2" class="slide level2">
<h2>Try it out</h2>
<ul>
<li class="fragment">see â€œBayes factor scale interpretationâ€</li>
<li class="fragment"><code>notebooks/probability distributions.ipynb</code></li>
</ul>
</section>
<section id="example-guessing-vs.-non-guessing" class="slide level2">
<h2>Example: guessing vs.&nbsp;non-guessing</h2>
<ul>
<li class="fragment">9 out of 10 trials correct â†’ <span class="math inline">\(k = 9\)</span>, <span class="math inline">\(n = 10\)</span><br>
</li>
<li class="fragment"><span class="math inline">\(M_1\)</span>: unknown ability â†’ <span class="math inline">\(\theta \sim \text{Uniform}(0,1)\)</span><br>
</li>
<li class="fragment"><span class="math inline">\(M_2\)</span>: guessing â†’ <span class="math inline">\(\theta = 0.5\)</span><br>
</li>
<li class="fragment">Compute marginal likelihood under each model<br>
</li>
<li class="fragment">Compare with a Bayes factor</li>
</ul>
</section>
<section id="bayes-factor-calculation" class="slide level2">
<h2>Bayes factor calculation</h2>
<ul>
<li class="fragment">For <span class="math inline">\(M_1\)</span>: <span class="math inline">\(p(D \mid M_1) = \frac{1}{1+n} = \frac{1}{11} \approx 0.0909\)</span><br>
</li>
<li class="fragment">For <span class="math inline">\(M_2\)</span>: <span class="math inline">\(p(D \mid M_2) = \binom{10}{9} (0.5)^{10} = 10 \cdot 0.000976 = 0.0098\)</span><br>
</li>
<li class="fragment">Bayes factor:<br>
<span class="math inline">\(BF_{12} = \frac{0.0909}{0.0098} \approx 9.3\)</span><br>
</li>
<li class="fragment">Data is about 9Ã— more likely under <span class="math inline">\(M_1\)</span> than <span class="math inline">\(M_2\)</span></li>
</ul>
</section>
<section id="try-it-out-3" class="slide level2">
<h2>Try it out</h2>
<ul>
<li class="fragment">see â€œBayes factor calculation step by stepâ€</li>
<li class="fragment"><code>notebooks/probability distributions.ipynb</code></li>
</ul>
</section>
<section id="flipping-the-bf" class="slide level2">
<h2>Flipping the BF</h2>
<ul>
<li class="fragment">If <span class="math inline">\(BF_{12} &lt; 1\)</span>â€¦</li>
<li class="fragment">â€¦take the reciprocal: <span class="math inline">\(BF_{21} = \frac{1}{BF_{12}}\)</span><br>
</li>
<li class="fragment">Keeps interpretation intuitive: how many times more likely is the data?<br>
</li>
<li class="fragment">Example: <span class="math inline">\(BF_{12} = 0.2\)</span> â†’ <span class="math inline">\(BF_{21} = 5\)</span><br>
</li>
<li class="fragment">Now we say: data is 5 Ã— more likely under <span class="math inline">\(M_2\)</span><br>
</li>
<li class="fragment">Same info, more digestible</li>
</ul>
</section>
<section id="bayes-vs.-fisher" class="slide level2">
<h2>Bayes vs.&nbsp;Fisher</h2>
<ul>
<li class="fragment">Bayes compares models<br>
</li>
<li class="fragment">Fisherian methods tests a single null hypothesis<br>
</li>
<li class="fragment">p-values ask: â€œhow unlikely is this data under <span class="math inline">\(H_0\)</span>?â€<br>
</li>
<li class="fragment">Bayes factors ask: â€œwhich model better explains the data?â€<br>
</li>
<li class="fragment">Evidence is always comparative: <span class="math inline">\(p(\text{data} \mid \text{A})\)</span> vs.&nbsp;<span class="math inline">\(p(\text{data} \mid \text{B})\)</span></li>
</ul>
</section>
<section id="critiques" class="slide level2">
<h2>Critiques</h2>
<ul>
<li class="fragment"><p><strong>Criticism:</strong> <em>Bayes factors are sensitive to prior choice</em><br>
</p></li>
<li class="fragment"><p><strong>Answer:</strong> This is a <strong>feature</strong> â€” priors are part of the model.</p></li>
<li class="fragment"><p><strong>Criticism:</strong> <em>But I donâ€™t want my conclusions to depend so much on the prior</em><br>
</p></li>
<li class="fragment"><p><strong>Answer:</strong> Then use <strong>sensitivity analysis</strong> to check robustness.</p></li>
<li class="fragment"><p><strong>Criticism:</strong> <em>BFs be high if one bad model is much worse than another</em><br>
</p></li>
<li class="fragment"><p><strong>Answer:</strong> True. Check <strong>descriptive adequacy</strong> â€” look at <strong>posterior predictive distributions</strong>, simulate data, or compare out-of-sample predictions.</p></li>
</ul>
</section>
<section id="the-arc-of-civilisation" class="slide level2">
<h2>The arc of civilisation</h2>
<ul>
<li class="fragment"><p>Oppposable thumbs, fire, the wheel, writing, zero, the printing press, Newtonian physics, germ theory, the steam engine, the combustion engine, the Moon landing, In Rainbows, the internet, CRISPR, Bayes factors</p></li>
<li class="fragment"><p><sub><span style="color:gray"><em>Iâ€™m being satirical (kinda).</em></span></sub></p></li>
</ul>
<!-- #endregion                             -->
<!-- #region Lecture#7 Posterior odds -->
</section></section>
<section>
<section id="posterior-odds" class="title-slide slide level1 center">
<h1>Posterior odds</h1>
<ul>
<li class="fragment">From Bayes factors to posterior model plausibility<br>
</li>
<li class="fragment">Combining likelihood and prior beliefs<br>
</li>
<li class="fragment">Posterior odds: what we believe after seeing the data<br>
</li>
<li class="fragment">Why priors matter<br>
</li>
<li class="fragment">Common critiques and computational issues</li>
</ul>
</section>
<section id="from-bayes-factor-to-posterior-odds" class="slide level2">
<h2>From Bayes factor to posterior odds</h2>
<ul>
<li class="fragment">Bayes factors compare predictive performance<br>
</li>
<li class="fragment">But model plausibility also depends on prior belief<br>
</li>
<li class="fragment">Posterior odds = updated belief in models after data<br>
</li>
<li class="fragment">Combines evidence (likelihood) and belief (prior)<br>
</li>
<li class="fragment">This gives a more complete model comparison</li>
</ul>
</section>
<section id="posterior-odds-equation" class="slide level2">
<h2>Posterior odds equation</h2>
<ul>
<li class="fragment">Relative plausibility:<br>
<span class="math inline">\(\frac{p(M_1 \mid D)}{p(M_2 \mid D)} = \frac{p(D \mid M_1)}{p(D \mid M_2)} \cdot \frac{p(M_1)}{p(M_2)}\)</span><br>
</li>
<li class="fragment">In words:<br>
posterior odds = Bayes factor Ã— prior odds<br>
</li>
<li class="fragment">Clear separation of belief and data<br>
</li>
<li class="fragment">Makes assumptions explicit<br>
</li>
<li class="fragment">Encourages transparency in modeling</li>
</ul>
</section>
<section id="posterior-odds-example" class="slide level2">
<h2>Posterior odds example</h2>
<ul>
<li class="fragment"><img data-src="images/posterior_odds_rain.png"></li>
</ul>
</section>
<section id="posterior-odds-schematic" class="slide level2">
<h2>Posterior odds schematic</h2>
<ul>
<li class="fragment"><img data-src="images/posterior_odds_eq.png"></li>
</ul>
</section>
<section id="try-it-out-4" class="slide level2">
<h2>Try it out</h2>
<ul>
<li class="fragment">This demo ties everything together!</li>
<li class="fragment"><code>notebooks/probability distributions.ipynb</code></li>
<li class="fragment">Go to â€œposterior odds calculationâ€</li>
</ul>
</section>
<section id="transforming-prior-into-posterior" class="slide level2">
<h2>Transforming prior into posterior</h2>
<ul>
<li class="fragment">Bayes factor converts prior odds into posterior odds<br>
</li>
<li class="fragment">If prior odds = 1, posterior odds = Bayes factor<br>
</li>
<li class="fragment">Prior beliefs influence conclusions<br>
</li>
<li class="fragment">But can be updated rationally with data<br>
</li>
<li class="fragment">Thatâ€™s the power of Bayes</li>
</ul>
</section>
<section id="why-bayes-factors-are-powerful" class="slide level2">
<h2>Why Bayes factors are powerful</h2>
<ul>
<li class="fragment">Automatically penalize overly complex models<br>
</li>
<li class="fragment">Allow direct evidence for the null<br>
</li>
<li class="fragment">Can handle multiple models, not just null vs.&nbsp;alt<br>
</li>
<li class="fragment">Support sequential data collection<br>
</li>
<li class="fragment">Intuitive: how much more likely is the data?</li>
</ul>
</section>
<section id="extraordinary-claims-extraordinary-evidence" class="slide level2">
<h2>Extraordinary claims, extraordinary evidence</h2>
<ul>
<li class="fragment">Strong priors require stronger data<br>
</li>
<li class="fragment"><span class="math inline">\(p(M \mid D) = BF \cdot p(M)\)</span><br>
</li>
<li class="fragment">Even big Bayes factors may not sway implausible models<br>
</li>
<li class="fragment">Prior odds encode skepticism<br>
</li>
<li class="fragment">Bayesian methods make this explicit</li>
</ul>
</section>
<section id="why-p-values-cant-do-this" class="slide level2">
<h2>Why p-values canâ€™t do this</h2>
<ul>
<li class="fragment">p-values donâ€™t compare models<br>
</li>
<li class="fragment">Donâ€™t provide evidence for the null<br>
</li>
<li class="fragment">Depend on hypothetical outcomes<br>
</li>
<li class="fragment">Require fixed plans to be valid<br>
</li>
<li class="fragment">Canâ€™t say â€œthis model is betterâ€</li>
</ul>
</section>
<section id="optional-stopping" class="slide level2">
<h2>Optional stopping</h2>
<ul>
<li class="fragment">Bayes allows data collection to stop anytime<br>
</li>
<li class="fragment">p-values require pre-specified <span class="math inline">\(n\)</span><br>
</li>
<li class="fragment">Bayes factors stay valid during interim checks<br>
</li>
<li class="fragment">Enables adaptive design<br>
</li>
<li class="fragment">More flexible, more realistic</li>
</ul>
</section>
<section id="conceptual-and-computational-challenges" class="slide level2">
<h2>Conceptual and computational challenges</h2>
<ul>
<li class="fragment">Priors matter: vague priors can be a liability because they can make a model bad</li>
<li class="fragment">Marginal likelihood is sometimes hard to compute<br>
</li>
<li class="fragment">Complex models need careful approximation<br>
</li>
<li class="fragment">Broad priors lower predictive accuracy<br>
</li>
<li class="fragment">Precision in priors improves inference</li>
</ul>
</section>
<section id="specifying-priors" class="slide level2">
<h2>Specifying priors</h2>
<ul>
<li class="fragment">Priors must reflect real uncertainty<br>
</li>
<li class="fragment">Two strategies:
<ul>
<li class="fragment">Subjective (expert-driven)<br>
</li>
<li class="fragment">Objective (e.g., unit-information priors)<br>
</li>
</ul></li>
<li class="fragment">Objective priors = default baseline<br>
</li>
<li class="fragment">Useful for reproducibility<br>
</li>
<li class="fragment">Can be refined with context</li>
</ul>
</section>
<section id="common-confusion-about-priors" class="slide level2">
<h2>Common confusion about priors</h2>
<ul>
<li class="fragment">Model priors are priors over models, parameter priors are priors over parameters.</li>
<li class="fragment">Bayes factor does <strong>not</strong> depend on model priors<br>
</li>
<li class="fragment">It <strong>does</strong> depend on parameter priors because these are part of models</li>
<li class="fragment">Posterior model probability depends on both<br>
</li>
<li class="fragment">So:
<ul>
<li class="fragment">Priors on models â†’ posterior odds<br>
</li>
<li class="fragment">Priors on parameters â†’ Bayes factor</li>
</ul></li>
</ul>
</section>
<section id="prior-sensitivity" class="slide level2">
<h2>Prior sensitivity</h2>
<ul>
<li class="fragment">Different priors = different conclusions<br>
</li>
<li class="fragment">Thatâ€™s not a bug â€” itâ€™s honest uncertainty<br>
</li>
<li class="fragment">Test robustness with sensitivity analysis<br>
</li>
<li class="fragment">Try narrower and wider priors<br>
</li>
<li class="fragment">Some models are robust, others fragile</li>
</ul>
</section>
<section id="computational-solutions" class="slide level2">
<h2>Computational solutions</h2>
<ul>
<li class="fragment">Exact marginal likelihood often unavailable<br>
</li>
<li class="fragment">Approximate methods include:
<ul>
<li class="fragment">Free energy minimisation</li>
<li class="fragment">Variational Bayes</li>
<li class="fragment">MCMC methods <em>like we have used</em></li>
</ul></li>
</ul>
<!-- #endregion -->
<!-- #region Misc lectures -->
<!-- #region Lecture#9 Savage Dickey -->
</section></section>
<section>
<section id="savage-dickkey-method-of-model-comparison" class="title-slide slide level1 center">
<h1>Savage-Dickkey method of model comparison</h1>
<ul>
<li class="fragment">In this method two models are compared:
<ul>
<li class="fragment"><strong>Null hypothesis (<span class="math inline">\(H_0\)</span>)</strong>: fixes parameter to a specific value, e.g., <span class="math inline">\(\phi = \phi_0\)</span></li>
<li class="fragment"><strong>Alternative hypothesis (<span class="math inline">\(H_1\)</span>)</strong>: parameter free to vary, e.g., <span class="math inline">\(\phi \ne \phi_0\)</span></li>
</ul></li>
<li class="fragment"><span class="math inline">\(H_0\)</span> is nested within <span class="math inline">\(H_1\)</span> (by constraining parameter).</li>
<li class="fragment">Classical null hypothesis usually sharp (point-null).</li>
</ul>
</section>
<section id="savagedickey-density-ratio" class="slide level2">
<h2>Savageâ€“Dickey Density Ratio</h2>
<ul>
<li class="fragment">Defines Bayes factor for nested models: <span class="math inline">\(BF_{01} = \frac{p(D \mid H_0)}{p(D \mid H_1)} = \frac{p(\phi = \phi_0 \mid D, H_1)}{p(\phi = \phi_0 \mid H_1)}\)</span></li>
<li class="fragment">Simply the ratio of posterior to prior densities at the point of interest <span class="math inline">\(\phi_0\)</span> under the alternative hypothesis.</li>
</ul>
</section>
<section id="example-binomial-scenario" class="slide level2">
<h2>Example: Binomial Scenario</h2>
<ul>
<li class="fragment">Binomial scenario: <span class="math inline">\(\theta\)</span> parameter, observing 9 correct and 1 incorrect response.</li>
<li class="fragment">Null hypothesis (<span class="math inline">\(H_0\)</span>): <span class="math inline">\(\theta = 0.5\)</span></li>
<li class="fragment">Alternative hypothesis (<span class="math inline">\(H_1\)</span>): <span class="math inline">\(\theta\)</span> free to vary, prior <span class="math inline">\(\theta \sim Beta(1,1)\)</span></li>
<li class="fragment">Bayes factor is the ratio of posterior and prior densities at <span class="math inline">\(\theta=0.5\)</span></li>
</ul>
</section>
<section id="visual-interpretation-of-savage-dickey" class="slide level2">
<h2>Visual Interpretation of Savage-Dickey</h2>
<ul>
<li class="fragment"><img data-src="Fig7.1-example.jpg"></li>
<li class="fragment">Prior (uniform) and posterior distributions shown.</li>
<li class="fragment">Density ratio at <span class="math inline">\(\theta=0.5\)</span> gives Bayes factor.</li>
</ul>
</section>
<section id="mcmc-based-estimation-for-savage-dickey" class="slide level2">
<h2>MCMC-Based Estimation for Savage-Dickey</h2>
<ul>
<li class="fragment">When analytical solutions are difficult, use MCMC: -<img data-src="Fig7.2-MCMC-example.jpg"></li>
<li class="fragment">Posterior and prior estimated from MCMC samples.</li>
<li class="fragment">Heights of posterior and prior at the null point give Bayes factor.</li>
</ul>
</section>
<section id="advantages-of-savagedickey" class="slide level2">
<h2>Advantages of Savageâ€“Dickey</h2>
<ul>
<li class="fragment">Direct interpretation as density ratio.</li>
<li class="fragment">Simplifies computation â€”no separate marginal likelihood calculation needed.</li>
<li class="fragment">Works well for nested models. <!-- #endregion    --></li>
</ul>
<!-- #region Lecture#10 Compare guassian means    -->
</section></section>
<section>
<section id="commpare-gaussian-means" class="title-slide slide level1 center">
<h1>Commpare Gaussian means</h1>
<ul>
<li class="fragment">Common task: test if two Gaussian means differ</li>
<li class="fragment">Example: does glucose improve detection performance</li>
<li class="fragment">Focus: test claim that glucose boost has larger effect in summer</li>
</ul>
</section>
<section id="data" class="slide level2">
<h2>Data</h2>
<table class="caption-top">
<thead>
<tr class="header">
<th>Season</th>
<th>N</th>
<th>Mean</th>
<th>SD</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Winter</td>
<td>41</td>
<td>0.11</td>
<td>0.15</td>
</tr>
<tr class="even">
<td>Summer</td>
<td>41</td>
<td>0.07</td>
<td>0.23</td>
</tr>
</tbody>
</table>
<ul>
<li class="fragment">Difference not significant<br>
</li>
<li class="fragment">t = 0.79, p = 0.44</li>
</ul>
</section>
<section id="p-values-and-the-null-hypothesis" class="slide level2">
<h2>p-values and the Null Hypothesis</h2>
<ul>
<li class="fragment">â€œFrom a null result, we cannot conclude that no difference existsâ€¦â€</li>
<li class="fragment">p = 0.44 does not support Hâ‚€</li>
<li class="fragment">It just means data are not incompatible with Hâ‚€</li>
<li class="fragment">Need a Bayes factor to quantify support for Hâ‚€</li>
</ul>
</section>
<section id="bayes-factor-overview" class="slide level2">
<h2>Bayes Factor Overview</h2>
<ul>
<li class="fragment">Bayes factor compares posterior vs prior odds</li>
<li class="fragment">Quantifies evidence for or against Hâ‚€</li>
<li class="fragment">Unlike p-values, can support Hâ‚€</li>
</ul>
</section>
<section id="one-sample-comparison-model" class="slide level2">
<h2>One-Sample Comparison Model</h2>
<ul>
<li class="fragment">Test standardized difference scores (e.g., winter - summer)</li>
<li class="fragment">Assume:
<ul>
<li class="fragment">Î´ ~ Cauchy(0,1)</li>
<li class="fragment">xáµ¢ ~ Gaussian(Î¼, 1/ÏƒÂ²)</li>
<li class="fragment">Î¼ = Î´Ïƒ</li>
</ul></li>
</ul>
</section>
<section id="one-sample-graphical-model" class="slide level2">
<h2>One-Sample Graphical Model</h2>
<ul>
<li class="fragment"><div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="figures/graphical_model_onesample.png"></p>
<figcaption>Fig 8.1</figcaption>
</figure>
</div></li>
<li class="fragment">Prior on Î´: Cauchy(0,1)</li>
<li class="fragment">Prior on Ïƒ: Half-Cauchy</li>
<li class="fragment">Estimate posterior with MCMC</li>
</ul>
</section>
<section id="posterior-vs-prior" class="slide level2">
<h2>Posterior vs Prior</h2>
<ul>
<li class="fragment"><div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="figures/posterior_prior_onesample.png"></p>
<figcaption>Figure 8.2</figcaption>
</figure>
</div></li>
<li class="fragment">Posterior peaks near Î´ = 0</li>
<li class="fragment">Bayes Factor â‰ˆ 5:1 in favor of Hâ‚€</li>
</ul>
</section>
<section id="order-restricted-model" class="slide level2">
<h2>Order-Restricted Model</h2>
<ul>
<li class="fragment">SMM predicts <strong>Î´ &lt; 0</strong></li>
<li class="fragment">Use order-restricted prior:
<ul>
<li class="fragment">Î´ ~ Cauchy(0,1) truncated to (-âˆ, 0)</li>
</ul></li>
</ul>
</section>
<section id="updated-bayes-factor" class="slide level2">
<h2>Updated Bayes Factor</h2>
<ul>
<li class="fragment"><div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="figures/posterior_prior_orderrestricted.png"></p>
<figcaption>Figure 8.4</figcaption>
</figure>
</div></li>
<li class="fragment">Stronger evidence for Hâ‚€: BF â‰ˆ 10:1</li>
</ul>
</section>
<section id="summary" class="slide level2">
<h2>Summary</h2>
<ul>
<li class="fragment">p-values canâ€™t confirm Hâ‚€</li>
<li class="fragment">Bayes factors can</li>
<li class="fragment">â€œEvidence of absenceâ€ of support for SMMâ€™s prediction</li>
</ul>
</section>
<section id="two-sample-comparison" class="slide level2">
<h2>Two-Sample Comparison</h2>
<ul>
<li class="fragment">Compare oxygenated vs plain water on memory</li>
<li class="fragment">Two independent groups</li>
</ul>
</section>
<section id="two-sample-model-structure" class="slide level2">
<h2>Two-Sample Model Structure</h2>
<ul>
<li class="fragment"><div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="figures/graphical_model_twosample.png"></p>
<figcaption>Figure 8.5</figcaption>
</figure>
</div></li>
<li class="fragment">Shared variance ÏƒÂ²</li>
<li class="fragment">Î´ = Î± / Ïƒ<br>
</li>
<li class="fragment">Î± = Î¼â‚“ - Î¼áµ§</li>
</ul>
</section>
<section id="large-effect-example" class="slide level2">
<h2>Large Effect Example</h2>
<table class="caption-top">
<thead>
<tr class="header">
<th>Group</th>
<th>N</th>
<th>Mean</th>
<th>SD</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Plain Water</td>
<td>20</td>
<td>68.35</td>
<td>6.38</td>
</tr>
<tr class="even">
<td>Oxygenated</td>
<td>20</td>
<td>76.65</td>
<td>4.06</td>
</tr>
<tr class="odd">
<td>t(38) = 4.47, p &lt; .01</td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
</section>
<section id="two-sample-bayes-factor" class="slide level2">
<h2>Two-Sample Bayes Factor</h2>
<p>-<img data-src="figures/posterior_prior_twosample.png" alt="Figure 8.6"> - Posterior moves away from 0 - BF â‰ˆ 447:1 in favor of Hâ‚<br>
- Decisive evidence for oxygenated water effect <!-- #endregion   --></p>
<!-- #region Lecture#11 Compare binomial rates    -->
</section></section>
<section>
<section id="comparing-binomial-rates" class="title-slide slide level1 center">
<h1>Comparing binomial rates</h1>
<ul>
<li class="fragment">We will naturally compute binomial rates for different groups or conditions</li>
<li class="fragment">And ask which is larger?</li>
<li class="fragment">We thus need to compare binomial rates and test hypotheses about which is bigger etc.</li>
</ul>
</section>
<section id="bayesian-graphical-model" class="slide level2">
<h2>Bayesian graphical model</h2>
<ul>
<li class="fragment"><div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="figures/Fig9.1.png"></p>
<figcaption>Figure 9.1</figcaption>
</figure>
</div></li>
<li class="fragment">graphical model for comparing two proportions</li>
</ul>
</section>
<section id="bayesian-model" class="slide level2">
<h2>Bayesian model</h2>
<ul>
<li class="fragment">We model the observed counts using binomial likelihoods and assign uniform Beta priors: s1 ~ Binomial(theta1, n1)<br>
s2 ~ Binomial(theta2, n2)<br>
theta1 ~ Beta(1, 1)<br>
theta2 ~ Beta(1, 1)<br>
delta &lt;- theta1 - theta2</li>
<li class="fragment">theta1:</li>
<li class="fragment">theta2:</li>
<li class="fragment">delta = theta1 - theta2: difference in proportions</li>
<li class="fragment">We are interested in the posterior distribution of delta.</li>
</ul>
</section>
<section id="model-code" class="slide level2">
<h2>Model Code</h2>
<p>Here is the model used for posterior simulation: model { theta1 ~ dbeta(1,1) theta2 ~ dbeta(1,1) delta &lt;- theta1 - theta2 s1 ~ dbin(theta1, n1) s2 ~ dbin(theta2, n2) theta1prior ~ dbeta(1,1) theta2prior ~ dbeta(1,1) deltaprior &lt;- theta1prior - theta2prior } This allows us to compare the prior and posterior density of delta at zero.</p>
</section>
<section id="prior-and-posterior-distributions" class="slide level2">
<h2>Prior and Posterior Distributions</h2>
<ul>
<li class="fragment"><div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="figures/Fig9.2.png"></p>
<figcaption>Figure 9.2</figcaption>
</figure>
</div></li>
<li class="fragment">We estimate the posterior distribution for the rate difference delta = theta1 - theta2 using Bayesian inference.</li>
<li class="fragment">The left plot shows prior and posterior distributions for delta across its full range.</li>
<li class="fragment">The right plot zooms in near delta = 0.</li>
<li class="fragment">This is used in the Savageâ€“Dickey density ratio to compute the Bayes factor.</li>
<li class="fragment">The Savageâ€“Dickey method compares: BF_01 = prior density at delta = 0 / posterior density at delta = 0</li>
</ul>
</section>
<section id="interpreting-the-bayes-factor-1" class="slide level2">
<h2>Interpreting the Bayes Factor</h2>
<ul>
<li class="fragment">The posterior density at delta = 0 is about half the prior density.</li>
<li class="fragment">This gives a Bayes factor â‰ˆ 2 in favor of the alternative hypothesis H1: delta â‰  0.</li>
<li class="fragment">The 95% credible interval for delta is approximately [-0.09, 0.01], which does not include 0.</li>
</ul>
<p><strong>Interpretation</strong>: - There is only modest evidence that one rate is higher than another - The Bayes factor penalizes H1 for spreading prior mass over implausible values. <!-- #endregion    --></p>
<!-- #region Lecture#4 Inference with Gaussians   -->
</section></section>
<section>
<section id="inferences-with-gaussians" class="title-slide slide level1 center">
<h1>Inferences with Gaussians</h1>
<ul>
<li class="fragment">Due to central limit theorem, data and parameters are frequently Gaussian</li>
<li class="fragment">Gaussians have 2 parameters, a mean and a measure of their spread</li>
<li class="fragment">Spread can be expressed as a variance, std, or a precision (1/var)</li>
</ul>
</section>
<section id="graphical-model-for-gaussians" class="slide level2">
<h2>Graphical model for Gaussians</h2>
<ul>
<li class="fragment">Simple model for inferring Gaussian with unknown mean and std</li>
<li class="fragment"><img data-src="fig.4.1.jpg"></li>
</ul>
</section>
<section id="interactive-demo-of-gaussian" class="slide level2">
<h2>Interactive demo of Gaussian</h2>
<ul>
<li class="fragment">Jupyter notebook - interactive plotting of gaussian</li>
</ul>
</section>
<section id="sampling-model-for-inferring-gaussians" class="slide level2">
<h2>Sampling model for inferring Gaussians</h2>
<p>model { for (i in 1:n){ x[i]~dnorm(mu,lambda) } mu~dnorm(0,0.001) sigma~dunif(0,10) lambda&lt;-1/pow(sigma,2) }</p>
</section>
<section id="repeated-measures-of-iq" class="slide level2">
<h2>Repeated measures of IQ</h2>
<ul>
<li class="fragment">Imagine taking a cognitive test like IQ multiple times</li>
<li class="fragment">The mean is your IQ, and the spread models fluctuations in your performance. e.g.&nbsp;attention, fatigue, emotion, venus orbitting satturn</li>
<li class="fragment">We can model this as a Gaussian for each person</li>
</ul>
</section>
<section id="graphical-model-for-iq" class="slide level2">
<h2>Graphical model for IQ</h2>
<ul>
<li class="fragment"><img data-src="fig.4.3.jpg"></li>
<li class="fragment">What parameter is common to all subjects?</li>
<li class="fragment">No index on the std. This means it is fixed.</li>
<li class="fragment">Is this justified?</li>
<li class="fragment">How to change it?</li>
</ul>
</section>
<section id="sampling-code-for-iq" class="slide level2">
<h2>Sampling code for IQ</h2>
<p>model{ for (i in 1:n) { for (j in 1:m) { x[i,j]~dnorm(mu[i],lambda) } } sigma~dunif(0,100) lambda &lt;-1/pow(sigma,2) for (i in 1:n) { mu([i]~ dunif(0,300)) }</p>
<p>} <!-- #endregion                            --></p>
<!-- #endregion -->

</section></section>
    </div>
  <div class="quarto-auto-generated-content" style="display: none;">
<div class="footer footer-default">
<p><a href="https://tinyurl.com/bayeBinderRepo" target="_blank"> tinyurl.com/bayesBinderRepo </a>&nbsp;&nbsp;&nbsp; <a href="https://tinyurl.com/bayesGithub" target="_blank"> tinyurl.com/bayesGithub </a>&nbsp;&nbsp;</p>
</div>
</div></div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="BayesianModels_slides_files/libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="BayesianModels_slides_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="BayesianModels_slides_files/libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="BayesianModels_slides_files/libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="BayesianModels_slides_files/libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="BayesianModels_slides_files/libs/revealjs/plugin/reveal-chalkboard/plugin.js"></script>
  <script src="BayesianModels_slides_files/libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="BayesianModels_slides_files/libs/revealjs/plugin/notes/notes.js"></script>
  <script src="BayesianModels_slides_files/libs/revealjs/plugin/search/search.js"></script>
  <script src="BayesianModels_slides_files/libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="BayesianModels_slides_files/libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': true,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'jumpToSlide': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleScrollView(event)\"><kbd>r</kbd> Scroll View Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleChalkboard(event)\"><kbd>b</kbd> Toggle Chalkboard</a></li>\n<li class=\"slide-tool-item\" data-item=\"6\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleNotesCanvas(event)\"><kbd>c</kbd> Toggle Notes Canvas</a></li>\n<li class=\"slide-tool-item\" data-item=\"7\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.downloadDrawings(event)\"><kbd>d</kbd> Download Drawings</a></li>\n<li class=\"slide-tool-item\" data-item=\"8\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'chalkboard': {"buttons":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'default',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, RevealChalkboard, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
    window.document.addEventListener("DOMContentLoaded", function (event) {
      const toggleBodyColorMode = (bsSheetEl) => {
        const mode = bsSheetEl.getAttribute("data-mode");
        const bodyEl = window.document.querySelector("body");
        if (mode === "dark") {
          bodyEl.classList.add("quarto-dark");
          bodyEl.classList.remove("quarto-light");
        } else {
          bodyEl.classList.add("quarto-light");
          bodyEl.classList.remove("quarto-dark");
        }
      }
      const toggleBodyColorPrimary = () => {
        const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
        if (bsSheetEl) {
          toggleBodyColorMode(bsSheetEl);
        }
      }
      toggleBodyColorPrimary();  
      const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
      tabsets.forEach(function(tabset) {
        const tabby = new Tabby('#' + tabset.id);
      });
      const isCodeAnnotation = (el) => {
        for (const clz of el.classList) {
          if (clz.startsWith('code-annotation-')) {                     
            return true;
          }
        }
        return false;
      }
      const onCopySuccess = function(e) {
        // button target
        const button = e.trigger;
        // don't keep focus
        button.blur();
        // flash "checked"
        button.classList.add('code-copy-button-checked');
        var currentTitle = button.getAttribute("title");
        button.setAttribute("title", "Copied!");
        let tooltip;
        if (window.bootstrap) {
          button.setAttribute("data-bs-toggle", "tooltip");
          button.setAttribute("data-bs-placement", "left");
          button.setAttribute("data-bs-title", "Copied!");
          tooltip = new bootstrap.Tooltip(button, 
            { trigger: "manual", 
              customClass: "code-copy-button-tooltip",
              offset: [0, -8]});
          tooltip.show();    
        }
        setTimeout(function() {
          if (tooltip) {
            tooltip.hide();
            button.removeAttribute("data-bs-title");
            button.removeAttribute("data-bs-toggle");
            button.removeAttribute("data-bs-placement");
          }
          button.setAttribute("title", currentTitle);
          button.classList.remove('code-copy-button-checked');
        }, 1000);
        // clear code selection
        e.clearSelection();
      }
      const getTextToCopy = function(trigger) {
          const codeEl = trigger.previousElementSibling.cloneNode(true);
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
      }
      const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
        text: getTextToCopy
      });
      clipboard.on('success', onCopySuccess);
      if (window.document.getElementById('quarto-embedded-source-code-modal')) {
        const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
          text: getTextToCopy,
          container: window.document.getElementById('quarto-embedded-source-code-modal')
        });
        clipboardModal.on('success', onCopySuccess);
      }
        var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
        var mailtoRegex = new RegExp(/^mailto:/);
          var filterRegex = new RegExp('/' + window.location.host + '/');
        var isInternal = (href) => {
            return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
        }
        // Inspect non-navigation links and adorn them if external
     	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
        for (var i=0; i<links.length; i++) {
          const link = links[i];
          if (!isInternal(link.href)) {
            // undo the damage that might have been done by quarto-nav.js in the case of
            // links that we want to consider external
            if (link.dataset.originalHref !== undefined) {
              link.href = link.dataset.originalHref;
            }
          }
        }
      function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
        const config = {
          allowHTML: true,
          maxWidth: 500,
          delay: 100,
          arrow: false,
          appendTo: function(el) {
              return el.closest('section.slide') || el.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'light-border',
          placement: 'bottom-start',
        };
        if (contentFn) {
          config.content = contentFn;
        }
        if (onTriggerFn) {
          config.onTrigger = onTriggerFn;
        }
        if (onUntriggerFn) {
          config.onUntrigger = onUntriggerFn;
        }
          config['offset'] = [0,0];
          config['maxWidth'] = 700;
        window.tippy(el, config); 
      }
      const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
      for (var i=0; i<noterefs.length; i++) {
        const ref = noterefs[i];
        tippyHover(ref, function() {
          // use id or data attribute instead here
          let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
          try { href = new URL(href).hash; } catch {}
          const id = href.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note) {
            return note.innerHTML;
          } else {
            return "";
          }
        });
      }
      const findCites = (el) => {
        const parentEl = el.parentElement;
        if (parentEl) {
          const cites = parentEl.dataset.cites;
          if (cites) {
            return {
              el,
              cites: cites.split(' ')
            };
          } else {
            return findCites(el.parentElement)
          }
        } else {
          return undefined;
        }
      };
      var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
      for (var i=0; i<bibliorefs.length; i++) {
        const ref = bibliorefs[i];
        const citeInfo = findCites(ref);
        if (citeInfo) {
          tippyHover(citeInfo.el, function() {
            var popup = window.document.createElement('div');
            citeInfo.cites.forEach(function(cite) {
              var citeDiv = window.document.createElement('div');
              citeDiv.classList.add('hanging-indent');
              citeDiv.classList.add('csl-entry');
              var biblioDiv = window.document.getElementById('ref-' + cite);
              if (biblioDiv) {
                citeDiv.innerHTML = biblioDiv.innerHTML;
              }
              popup.appendChild(citeDiv);
            });
            return popup.innerHTML;
          });
        }
      }
    });
    </script>
    

</body></html>